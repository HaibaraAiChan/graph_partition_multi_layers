Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1648488772.136524
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0010123252868652344  GigaBytes
Max Memory Allocated: 0.0010123252868652344  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.024713754653930664
range selection method range initialization spend 0.013330698013305664
time for parepare:  0.017729520797729492
local_output_nid generation:  0.010607004165649414
local_in_edges_tensor generation:  0.010215520858764648
mini_batch_src_global generation:  0.013917207717895508
r_  generation:  0.16975712776184082
local_output_nid generation:  0.012042522430419922
local_in_edges_tensor generation:  0.01082301139831543
mini_batch_src_global generation:  0.016768693923950195
r_  generation:  0.178788423538208
----------------------check_connections_block total spend ----------------------------- 0.5096230506896973
generate_one_block  0.1990654468536377
generate_one_block  0.20038461685180664
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.042287588119506836
gen group dst list time:  0.007344245910644531
time for parepare:  0.019838333129882812
local_output_nid generation:  0.017089366912841797
local_in_edges_tensor generation:  0.04257464408874512
mini_batch_src_global generation:  0.04608488082885742
r_  generation:  0.4936487674713135
local_output_nid generation:  0.02742624282836914
local_in_edges_tensor generation:  0.045459747314453125
mini_batch_src_global generation:  0.05665755271911621
r_  generation:  0.5121431350708008
----------------------check_connections_block total spend ----------------------------- 1.478186845779419
generate_one_block  0.6528387069702148
generate_one_block  0.660369873046875
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.03526663780212402
gen group dst list time:  0.015079736709594727
time for parepare:  0.01890420913696289
local_output_nid generation:  0.021686315536499023
local_in_edges_tensor generation:  0.040224313735961914
mini_batch_src_global generation:  0.049172163009643555
r_  generation:  0.5489072799682617
local_output_nid generation:  0.031225919723510742
local_in_edges_tensor generation:  0.05412030220031738
mini_batch_src_global generation:  0.06412053108215332
r_  generation:  0.55771803855896
----------------------check_connections_block total spend ----------------------------- 1.62559175491333
generate_one_block  0.7229235172271729
generate_one_block  0.7130892276763916
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.02689051628112793
gen group dst list time:  0.012356996536254883
time for parepare:  0.01919865608215332
local_output_nid generation:  0.02293705940246582
local_in_edges_tensor generation:  0.03440046310424805
mini_batch_src_global generation:  0.04544711112976074
r_  generation:  0.518211841583252
local_output_nid generation:  0.03221464157104492
local_in_edges_tensor generation:  0.03895139694213867
mini_batch_src_global generation:  0.05724382400512695
r_  generation:  0.5270774364471436
----------------------check_connections_block total spend ----------------------------- 1.5270202159881592
generate_one_block  0.6403372287750244
generate_one_block  0.6608142852783203
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0010123252868652344  GigaBytes
Max Memory Allocated: 0.0010123252868652344  GigaBytes

connection checking time:  4.630798816680908
block generation total time  4.050372838973999
average batch blocks generation time:  2.0251864194869995
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2205810546875 GB
    Memory Allocated: 0.12077808380126953  GigaBytes
Max Memory Allocated: 0.12077808380126953  GigaBytes

torch.Size([167381, 128])
torch.Size([166651, 64])
torch.Size([162826, 64])
Traceback (most recent call last):
  File "pseudo_mini_batch_range_arxiv_sage.py", line 435, in <module>
    main()
  File "pseudo_mini_batch_range_arxiv_sage.py", line 431, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_arxiv_sage.py", line 251, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 182, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.62 GiB total capacity; 22.36 GiB already allocated; 10.44 MiB free; 22.41 GiB reserved in total by PyTorch)
