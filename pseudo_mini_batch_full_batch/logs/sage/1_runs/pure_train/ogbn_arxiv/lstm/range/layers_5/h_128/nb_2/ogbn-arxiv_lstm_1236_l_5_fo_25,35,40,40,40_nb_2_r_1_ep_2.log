Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1648506411.1399524
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0029964447021484375  GigaBytes
Max Memory Allocated: 0.0029964447021484375  GigaBytes

The real block id is  4
get_global_graph_edges_ids_block function  spend 0.02484607696533203
range selection method range initialization spend 0.013534069061279297
time for parepare:  0.017651796340942383
local_output_nid generation:  0.010448694229125977
local_in_edges_tensor generation:  0.01018071174621582
mini_batch_src_global generation:  0.013925552368164062
r_  generation:  0.16808032989501953
local_output_nid generation:  0.011554479598999023
local_in_edges_tensor generation:  0.01072382926940918
mini_batch_src_global generation:  0.016712427139282227
r_  generation:  0.17702770233154297
----------------------check_connections_block total spend ----------------------------- 0.5041251182556152
generate_one_block  0.19855570793151855
generate_one_block  0.19847607612609863
The real block id is  3
get_global_graph_edges_ids_block function  spend 0.041909217834472656
gen group dst list time:  0.007406711578369141
time for parepare:  0.01925826072692871
local_output_nid generation:  0.016346216201782227
local_in_edges_tensor generation:  0.04335474967956543
mini_batch_src_global generation:  0.05015873908996582
r_  generation:  0.4956693649291992
local_output_nid generation:  0.02472376823425293
local_in_edges_tensor generation:  0.044945478439331055
mini_batch_src_global generation:  0.06071901321411133
r_  generation:  0.5018136501312256
----------------------check_connections_block total spend ----------------------------- 1.4730632305145264
generate_one_block  0.6396760940551758
generate_one_block  0.6483151912689209
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.03638267517089844
gen group dst list time:  0.011726856231689453
time for parepare:  0.019366741180419922
local_output_nid generation:  0.021058082580566406
local_in_edges_tensor generation:  0.039237260818481445
mini_batch_src_global generation:  0.05404210090637207
r_  generation:  0.5557382106781006
local_output_nid generation:  0.03415942192077637
local_in_edges_tensor generation:  0.050022125244140625
mini_batch_src_global generation:  0.06270790100097656
r_  generation:  0.5671775341033936
----------------------check_connections_block total spend ----------------------------- 1.6487631797790527
generate_one_block  0.7474734783172607
generate_one_block  0.7229170799255371
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.029779672622680664
gen group dst list time:  0.012301206588745117
time for parepare:  0.019167661666870117
local_output_nid generation:  0.02342677116394043
local_in_edges_tensor generation:  0.035750389099121094
mini_batch_src_global generation:  0.048361778259277344
r_  generation:  0.5547611713409424
local_output_nid generation:  0.03188967704772949
local_in_edges_tensor generation:  0.05125141143798828
mini_batch_src_global generation:  0.0627591609954834
r_  generation:  0.5647356510162354
----------------------check_connections_block total spend ----------------------------- 1.6429190635681152
generate_one_block  0.6946995258331299
generate_one_block  0.704343318939209
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.028390169143676758
gen group dst list time:  0.012464046478271484
time for parepare:  0.019085168838500977
local_output_nid generation:  0.023518085479736328
local_in_edges_tensor generation:  0.03429126739501953
mini_batch_src_global generation:  0.04581403732299805
r_  generation:  0.5119850635528564
local_output_nid generation:  0.03184032440185547
local_in_edges_tensor generation:  0.030740022659301758
mini_batch_src_global generation:  0.05845475196838379
r_  generation:  0.5220837593078613
----------------------check_connections_block total spend ----------------------------- 1.5120859146118164
generate_one_block  0.6369142532348633
generate_one_block  0.6488299369812012
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0029964447021484375  GigaBytes
Max Memory Allocated: 0.0029964447021484375  GigaBytes

connection checking time:  6.276831388473511
block generation total time  5.443168878555298
average batch blocks generation time:  2.721584439277649
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2225341796875 GB
    Memory Allocated: 0.13599157333374023  GigaBytes
Max Memory Allocated: 0.13599157333374023  GigaBytes

torch.Size([167820, 128])
torch.Size([167562, 128])
Traceback (most recent call last):
  File "pseudo_mini_batch_range_arxiv_sage.py", line 435, in <module>
    main()
  File "pseudo_mini_batch_range_arxiv_sage.py", line 431, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_arxiv_sage.py", line 251, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 182, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.62 GiB total capacity; 22.36 GiB already allocated; 6.44 MiB free; 22.42 GiB reserved in total by PyTorch)
