Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1648490230.6072633
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0233154296875 GB
    Memory Allocated: 0.007684230804443359  GigaBytes
Max Memory Allocated: 0.007684230804443359  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.024697065353393555
range selection method range initialization spend 0.013356208801269531
time for parepare:  0.017882347106933594
local_output_nid generation:  0.0052225589752197266
local_in_edges_tensor generation:  0.006036281585693359
mini_batch_src_global generation:  0.006426095962524414
r_  generation:  0.08162617683410645
local_output_nid generation:  0.00612950325012207
local_in_edges_tensor generation:  0.0030548572540283203
mini_batch_src_global generation:  0.00853109359741211
r_  generation:  0.08738088607788086
local_output_nid generation:  0.006181240081787109
local_in_edges_tensor generation:  0.0030765533447265625
mini_batch_src_global generation:  0.0066106319427490234
r_  generation:  0.08873581886291504
local_output_nid generation:  0.006235837936401367
local_in_edges_tensor generation:  0.0031347274780273438
mini_batch_src_global generation:  0.006816864013671875
r_  generation:  0.09055066108703613
----------------------check_connections_block total spend ----------------------------- 0.5033750534057617
generate_one_block  0.10103249549865723
generate_one_block  0.10228228569030762
generate_one_block  0.10336422920227051
generate_one_block  0.10248541831970215
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.040853023529052734
gen group dst list time:  0.011196374893188477
time for parepare:  0.019048452377319336
local_output_nid generation:  0.01471567153930664
local_in_edges_tensor generation:  0.037320613861083984
mini_batch_src_global generation:  0.04107356071472168
r_  generation:  0.40659594535827637
local_output_nid generation:  0.021285057067871094
local_in_edges_tensor generation:  0.03774547576904297
mini_batch_src_global generation:  0.060590505599975586
r_  generation:  0.4111766815185547
local_output_nid generation:  0.022034645080566406
local_in_edges_tensor generation:  0.031145334243774414
mini_batch_src_global generation:  0.04753708839416504
r_  generation:  0.4242410659790039
local_output_nid generation:  0.0224301815032959
local_in_edges_tensor generation:  0.02459263801574707
mini_batch_src_global generation:  0.04888749122619629
r_  generation:  0.4208967685699463
----------------------check_connections_block total spend ----------------------------- 2.4477832317352295
generate_one_block  0.5632147789001465
generate_one_block  0.5428507328033447
generate_one_block  0.5447685718536377
generate_one_block  0.5387105941772461
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.036193132400512695
gen group dst list time:  0.02068018913269043
time for parepare:  0.019143104553222656
local_output_nid generation:  0.024448633193969727
local_in_edges_tensor generation:  0.03879117965698242
mini_batch_src_global generation:  0.051847219467163086
r_  generation:  0.526759147644043
local_output_nid generation:  0.03565859794616699
local_in_edges_tensor generation:  0.054099321365356445
mini_batch_src_global generation:  0.06116175651550293
r_  generation:  0.5325877666473389
local_output_nid generation:  0.037308692932128906
local_in_edges_tensor generation:  0.03761100769042969
mini_batch_src_global generation:  0.06036186218261719
r_  generation:  0.5434310436248779
local_output_nid generation:  0.03740549087524414
local_in_edges_tensor generation:  0.03743886947631836
mini_batch_src_global generation:  0.05593705177307129
r_  generation:  0.5471317768096924
----------------------check_connections_block total spend ----------------------------- 3.1620805263519287
generate_one_block  0.6746993064880371
generate_one_block  0.6883339881896973
generate_one_block  0.6897439956665039
generate_one_block  0.6840429306030273
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.02832508087158203
gen group dst list time:  0.02386188507080078
time for parepare:  0.01888561248779297
local_output_nid generation:  0.026365041732788086
local_in_edges_tensor generation:  0.03819990158081055
mini_batch_src_global generation:  0.045479536056518555
r_  generation:  0.5028517246246338
local_output_nid generation:  0.034311532974243164
local_in_edges_tensor generation:  0.05167961120605469
mini_batch_src_global generation:  0.05995035171508789
r_  generation:  0.5111830234527588
local_output_nid generation:  0.034503936767578125
local_in_edges_tensor generation:  0.03883790969848633
mini_batch_src_global generation:  0.061144113540649414
r_  generation:  0.512322187423706
local_output_nid generation:  0.03526568412780762
local_in_edges_tensor generation:  0.04469561576843262
mini_batch_src_global generation:  0.05790853500366211
r_  generation:  0.5122439861297607
----------------------check_connections_block total spend ----------------------------- 3.048234224319458
generate_one_block  0.6830739974975586
generate_one_block  0.6492564678192139
generate_one_block  0.6482386589050293
generate_one_block  0.646775484085083
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0233154296875 GB
    Memory Allocated: 0.007684230804443359  GigaBytes
Max Memory Allocated: 0.007684230804443359  GigaBytes

connection checking time:  8.658097982406616
block generation total time  7.553709506988525
average batch blocks generation time:  1.8884273767471313
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2088623046875 GB
    Memory Allocated: 0.12362813949584961  GigaBytes
Max Memory Allocated: 0.12362813949584961  GigaBytes

torch.Size([166750, 128])
torch.Size([164871, 256])
Traceback (most recent call last):
  File "pseudo_mini_batch_range_arxiv_sage.py", line 435, in <module>
    main()
  File "pseudo_mini_batch_range_arxiv_sage.py", line 431, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_arxiv_sage.py", line 251, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 182, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.62 GiB total capacity; 22.02 GiB already allocated; 4.44 MiB free; 22.42 GiB reserved in total by PyTorch)
