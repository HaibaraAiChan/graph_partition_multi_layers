Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1648489772.7595541
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.002379894256591797  GigaBytes
Max Memory Allocated: 0.002379894256591797  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.02391219139099121
range selection method range initialization spend 0.0138397216796875
time for parepare:  0.0180816650390625
local_output_nid generation:  0.00536036491394043
local_in_edges_tensor generation:  0.005808353424072266
mini_batch_src_global generation:  0.0065975189208984375
r_  generation:  0.08294057846069336
local_output_nid generation:  0.006016254425048828
local_in_edges_tensor generation:  0.002969503402709961
mini_batch_src_global generation:  0.008444070816040039
r_  generation:  0.08830690383911133
local_output_nid generation:  0.006136178970336914
local_in_edges_tensor generation:  0.0030639171600341797
mini_batch_src_global generation:  0.006421566009521484
r_  generation:  0.0893697738647461
local_output_nid generation:  0.006079673767089844
local_in_edges_tensor generation:  0.0029714107513427734
mini_batch_src_global generation:  0.007050514221191406
r_  generation:  0.09263944625854492
----------------------check_connections_block total spend ----------------------------- 0.5091054439544678
generate_one_block  0.10126757621765137
generate_one_block  0.1016693115234375
generate_one_block  0.10264301300048828
generate_one_block  0.10248661041259766
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.03934359550476074
gen group dst list time:  0.01149129867553711
time for parepare:  0.019098520278930664
local_output_nid generation:  0.014674901962280273
local_in_edges_tensor generation:  0.034271955490112305
mini_batch_src_global generation:  0.040764570236206055
r_  generation:  0.40535664558410645
local_output_nid generation:  0.021460294723510742
local_in_edges_tensor generation:  0.036318063735961914
mini_batch_src_global generation:  0.04787492752075195
r_  generation:  0.4133157730102539
local_output_nid generation:  0.022227048873901367
local_in_edges_tensor generation:  0.033460140228271484
mini_batch_src_global generation:  0.048052310943603516
r_  generation:  0.4250776767730713
local_output_nid generation:  0.0224912166595459
local_in_edges_tensor generation:  0.022655248641967773
mini_batch_src_global generation:  0.049163818359375
r_  generation:  0.4239523410797119
----------------------check_connections_block total spend ----------------------------- 2.4333934783935547
generate_one_block  0.5610928535461426
generate_one_block  0.5417594909667969
generate_one_block  0.5540838241577148
generate_one_block  0.5363092422485352
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.03291130065917969
gen group dst list time:  0.02092266082763672
time for parepare:  0.019051790237426758
local_output_nid generation:  0.02419137954711914
local_in_edges_tensor generation:  0.038709163665771484
mini_batch_src_global generation:  0.04824399948120117
r_  generation:  0.5248637199401855
local_output_nid generation:  0.03569531440734863
local_in_edges_tensor generation:  0.04952096939086914
mini_batch_src_global generation:  0.060498952865600586
r_  generation:  0.5392487049102783
local_output_nid generation:  0.03581094741821289
local_in_edges_tensor generation:  0.041998863220214844
mini_batch_src_global generation:  0.05998349189758301
r_  generation:  0.5473225116729736
local_output_nid generation:  0.036524295806884766
local_in_edges_tensor generation:  0.03249645233154297
mini_batch_src_global generation:  0.05634737014770508
r_  generation:  0.5498225688934326
----------------------check_connections_block total spend ----------------------------- 3.161524534225464
generate_one_block  0.6711311340332031
generate_one_block  0.6852493286132812
generate_one_block  0.6985623836517334
generate_one_block  0.666884183883667
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.02514815330505371
gen group dst list time:  0.02354884147644043
time for parepare:  0.019050121307373047
local_output_nid generation:  0.0272979736328125
local_in_edges_tensor generation:  0.035500288009643555
mini_batch_src_global generation:  0.04442143440246582
r_  generation:  0.5021233558654785
local_output_nid generation:  0.03728485107421875
local_in_edges_tensor generation:  0.04488968849182129
mini_batch_src_global generation:  0.05716872215270996
r_  generation:  0.5109045505523682
local_output_nid generation:  0.03793907165527344
local_in_edges_tensor generation:  0.04152536392211914
mini_batch_src_global generation:  0.05975151062011719
r_  generation:  0.5119194984436035
local_output_nid generation:  0.03857827186584473
local_in_edges_tensor generation:  0.0366055965423584
mini_batch_src_global generation:  0.056853294372558594
r_  generation:  0.5163190364837646
----------------------check_connections_block total spend ----------------------------- 3.0265491008758545
generate_one_block  0.6605744361877441
generate_one_block  0.6373188495635986
generate_one_block  0.6599655151367188
generate_one_block  0.6426379680633545
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.002379894256591797  GigaBytes
Max Memory Allocated: 0.002379894256591797  GigaBytes

connection checking time:  8.621467113494873
block generation total time  7.51556921005249
average batch blocks generation time:  1.8788923025131226
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2049560546875 GB
    Memory Allocated: 0.11831998825073242  GigaBytes
Max Memory Allocated: 0.11831998825073242  GigaBytes

torch.Size([166683, 128])
torch.Size([164699, 128])
Traceback (most recent call last):
  File "pseudo_mini_batch_range_arxiv_sage.py", line 435, in <module>
    main()
  File "pseudo_mini_batch_range_arxiv_sage.py", line 431, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_arxiv_sage.py", line 251, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 182, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.62 GiB total capacity; 22.36 GiB already allocated; 12.44 MiB free; 22.41 GiB reserved in total by PyTorch)
