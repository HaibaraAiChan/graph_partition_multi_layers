Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1648502969.710602
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0029964447021484375  GigaBytes
Max Memory Allocated: 0.0029964447021484375  GigaBytes

The real block id is  4
get_global_graph_edges_ids_block function  spend 0.02519059181213379
random selection method range initialization spend 0.006412506103515625
time for parepare:  0.01868271827697754
local_output_nid generation:  0.0160067081451416
local_in_edges_tensor generation:  0.015286445617675781
mini_batch_src_global generation:  0.014636754989624023
r_  generation:  0.16817665100097656
local_output_nid generation:  0.021506786346435547
local_in_edges_tensor generation:  0.015802383422851562
mini_batch_src_global generation:  0.017926692962646484
r_  generation:  0.18142938613891602
----------------------check_connections_block total spend ----------------------------- 0.5495173931121826
generate_one_block  0.19945645332336426
generate_one_block  0.198991060256958
The real block id is  3
get_global_graph_edges_ids_block function  spend 0.0412142276763916
gen group dst list time:  0.0075113773345947266
time for parepare:  0.020108699798583984
local_output_nid generation:  0.02505970001220703
local_in_edges_tensor generation:  0.052066802978515625
mini_batch_src_global generation:  0.052217960357666016
r_  generation:  0.4960007667541504
local_output_nid generation:  0.03523063659667969
local_in_edges_tensor generation:  0.05051898956298828
mini_batch_src_global generation:  0.059313058853149414
r_  generation:  0.5093412399291992
----------------------check_connections_block total spend ----------------------------- 1.539506435394287
generate_one_block  0.6421129703521729
generate_one_block  0.6506397724151611
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.03696775436401367
gen group dst list time:  0.011846065521240234
time for parepare:  0.019857168197631836
local_output_nid generation:  0.030519485473632812
local_in_edges_tensor generation:  0.04869484901428223
mini_batch_src_global generation:  0.05802297592163086
r_  generation:  0.5585300922393799
local_output_nid generation:  0.04051041603088379
local_in_edges_tensor generation:  0.05482625961303711
mini_batch_src_global generation:  0.06613802909851074
r_  generation:  0.5674967765808105
----------------------check_connections_block total spend ----------------------------- 1.709608793258667
generate_one_block  0.7361917495727539
generate_one_block  0.7290163040161133
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.03052544593811035
gen group dst list time:  0.012578487396240234
time for parepare:  0.019676685333251953
local_output_nid generation:  0.03196239471435547
local_in_edges_tensor generation:  0.0453336238861084
mini_batch_src_global generation:  0.05374574661254883
r_  generation:  0.5480670928955078
local_output_nid generation:  0.04193377494812012
local_in_edges_tensor generation:  0.05501127243041992
mini_batch_src_global generation:  0.06516361236572266
r_  generation:  0.5591018199920654
----------------------check_connections_block total spend ----------------------------- 1.6892240047454834
generate_one_block  0.6890723705291748
generate_one_block  0.7044205665588379
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.027451038360595703
gen group dst list time:  0.012576103210449219
time for parepare:  0.019324064254760742
local_output_nid generation:  0.032584428787231445
local_in_edges_tensor generation:  0.04900360107421875
mini_batch_src_global generation:  0.0490725040435791
r_  generation:  0.5140666961669922
local_output_nid generation:  0.03835296630859375
local_in_edges_tensor generation:  0.04343008995056152
mini_batch_src_global generation:  0.06026577949523926
r_  generation:  0.513418436050415
----------------------check_connections_block total spend ----------------------------- 1.5800249576568604
generate_one_block  0.6408226490020752
generate_one_block  0.6728718280792236
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0029964447021484375  GigaBytes
Max Memory Allocated: 0.0029964447021484375  GigaBytes

connection checking time:  6.518364191055298
block generation total time  5.465148210525513
average batch blocks generation time:  2.7325741052627563
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2225341796875 GB
    Memory Allocated: 0.13600587844848633  GigaBytes
Max Memory Allocated: 0.13600587844848633  GigaBytes

torch.Size([167826, 128])
torch.Size([167575, 128])
Traceback (most recent call last):
  File "pseudo_mini_batch_range_arxiv_sage.py", line 435, in <module>
    main()
  File "pseudo_mini_batch_range_arxiv_sage.py", line 431, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_arxiv_sage.py", line 251, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 182, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.62 GiB total capacity; 22.33 GiB already allocated; 12.44 MiB free; 22.41 GiB reserved in total by PyTorch)
