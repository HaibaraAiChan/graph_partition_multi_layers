Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1648487294.2624085
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0233154296875 GB
    Memory Allocated: 0.007684230804443359  GigaBytes
Max Memory Allocated: 0.007684230804443359  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.02423572540283203
random selection method range initialization spend 0.0064465999603271484
time for parepare:  0.01838397979736328
local_output_nid generation:  0.008422136306762695
local_in_edges_tensor generation:  0.00887608528137207
mini_batch_src_global generation:  0.006407260894775391
r_  generation:  0.08103179931640625
local_output_nid generation:  0.011614799499511719
local_in_edges_tensor generation:  0.006036043167114258
mini_batch_src_global generation:  0.008621931076049805
r_  generation:  0.08878111839294434
local_output_nid generation:  0.011873245239257812
local_in_edges_tensor generation:  0.0059740543365478516
mini_batch_src_global generation:  0.006616830825805664
r_  generation:  0.08796477317810059
local_output_nid generation:  0.011801481246948242
local_in_edges_tensor generation:  0.006039619445800781
mini_batch_src_global generation:  0.007214069366455078
r_  generation:  0.0911712646484375
----------------------check_connections_block total spend ----------------------------- 0.5477566719055176
generate_one_block  0.10014009475708008
generate_one_block  0.10292387008666992
generate_one_block  0.1020205020904541
generate_one_block  0.10143566131591797
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.04136085510253906
gen group dst list time:  0.011512994766235352
time for parepare:  0.018860578536987305
local_output_nid generation:  0.019136905670166016
local_in_edges_tensor generation:  0.04405403137207031
mini_batch_src_global generation:  0.03864002227783203
r_  generation:  0.40172672271728516
local_output_nid generation:  0.0249478816986084
local_in_edges_tensor generation:  0.04145240783691406
mini_batch_src_global generation:  0.04802870750427246
r_  generation:  0.4126417636871338
local_output_nid generation:  0.02514958381652832
local_in_edges_tensor generation:  0.03400444984436035
mini_batch_src_global generation:  0.04775524139404297
r_  generation:  0.4212040901184082
local_output_nid generation:  0.025292634963989258
local_in_edges_tensor generation:  0.030286312103271484
mini_batch_src_global generation:  0.04985189437866211
r_  generation:  0.4214358329772949
----------------------check_connections_block total spend ----------------------------- 2.4735183715820312
generate_one_block  0.5624747276306152
generate_one_block  0.5567131042480469
generate_one_block  0.5435104370117188
generate_one_block  0.5520491600036621
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.03057408332824707
gen group dst list time:  0.02118825912475586
time for parepare:  0.018581151962280273
local_output_nid generation:  0.02931380271911621
local_in_edges_tensor generation:  0.04780459403991699
mini_batch_src_global generation:  0.05438709259033203
r_  generation:  0.5306665897369385
local_output_nid generation:  0.0364537239074707
local_in_edges_tensor generation:  0.05537819862365723
mini_batch_src_global generation:  0.06128549575805664
r_  generation:  0.5382366180419922
local_output_nid generation:  0.03642463684082031
local_in_edges_tensor generation:  0.046796321868896484
mini_batch_src_global generation:  0.05579113960266113
r_  generation:  0.5497868061065674
local_output_nid generation:  0.036257266998291016
local_in_edges_tensor generation:  0.04090309143066406
mini_batch_src_global generation:  0.05749034881591797
r_  generation:  0.5539305210113525
----------------------check_connections_block total spend ----------------------------- 3.231741189956665
generate_one_block  0.684319019317627
generate_one_block  0.6855833530426025
generate_one_block  0.6905138492584229
generate_one_block  0.6804594993591309
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.02750849723815918
gen group dst list time:  0.024182558059692383
time for parepare:  0.018741607666015625
local_output_nid generation:  0.03322029113769531
local_in_edges_tensor generation:  0.04282808303833008
mini_batch_src_global generation:  0.045111656188964844
r_  generation:  0.5044581890106201
local_output_nid generation:  0.0389094352722168
local_in_edges_tensor generation:  0.05181121826171875
mini_batch_src_global generation:  0.05718421936035156
r_  generation:  0.5096449851989746
local_output_nid generation:  0.0392308235168457
local_in_edges_tensor generation:  0.05228233337402344
mini_batch_src_global generation:  0.05721259117126465
r_  generation:  0.5104975700378418
local_output_nid generation:  0.03890824317932129
local_in_edges_tensor generation:  0.035665035247802734
mini_batch_src_global generation:  0.05751299858093262
r_  generation:  0.5117969512939453
----------------------check_connections_block total spend ----------------------------- 3.0763909816741943
generate_one_block  0.6619505882263184
generate_one_block  0.646082878112793
generate_one_block  0.6450843811035156
generate_one_block  0.627418041229248
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0233154296875 GB
    Memory Allocated: 0.007684230804443359  GigaBytes
Max Memory Allocated: 0.007684230804443359  GigaBytes

connection checking time:  8.78165054321289
block generation total time  7.536159038543701
average batch blocks generation time:  1.8840397596359253
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2088623046875 GB
    Memory Allocated: 0.12351083755493164  GigaBytes
Max Memory Allocated: 0.12351083755493164  GigaBytes

torch.Size([166673, 128])
torch.Size([164671, 256])
Traceback (most recent call last):
  File "pseudo_mini_batch_range_arxiv_sage.py", line 435, in <module>
    main()
  File "pseudo_mini_batch_range_arxiv_sage.py", line 431, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_arxiv_sage.py", line 251, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 182, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 23.62 GiB total capacity; 21.98 GiB already allocated; 6.44 MiB free; 22.42 GiB reserved in total by PyTorch)
