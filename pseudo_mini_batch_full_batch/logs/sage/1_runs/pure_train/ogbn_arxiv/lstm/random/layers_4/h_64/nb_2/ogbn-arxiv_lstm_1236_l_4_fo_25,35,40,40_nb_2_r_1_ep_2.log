Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1648485795.7846627
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0010123252868652344  GigaBytes
Max Memory Allocated: 0.0010123252868652344  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.024846553802490234
random selection method range initialization spend 0.006361722946166992
time for parepare:  0.01843738555908203
local_output_nid generation:  0.01611948013305664
local_in_edges_tensor generation:  0.014238595962524414
mini_batch_src_global generation:  0.013939380645751953
r_  generation:  0.16763806343078613
local_output_nid generation:  0.0217745304107666
local_in_edges_tensor generation:  0.015929222106933594
mini_batch_src_global generation:  0.01660633087158203
r_  generation:  0.17868947982788086
----------------------check_connections_block total spend ----------------------------- 0.5417451858520508
generate_one_block  0.1992194652557373
generate_one_block  0.19928598403930664
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.042203426361083984
gen group dst list time:  0.00740361213684082
time for parepare:  0.019088268280029297
local_output_nid generation:  0.02507758140563965
local_in_edges_tensor generation:  0.051799774169921875
mini_batch_src_global generation:  0.04520010948181152
r_  generation:  0.49631476402282715
local_output_nid generation:  0.031964778900146484
local_in_edges_tensor generation:  0.050627708435058594
mini_batch_src_global generation:  0.05706024169921875
r_  generation:  0.5133264064788818
----------------------check_connections_block total spend ----------------------------- 1.522789478302002
generate_one_block  0.6459329128265381
generate_one_block  0.6585078239440918
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.031046152114868164
gen group dst list time:  0.011810779571533203
time for parepare:  0.01945352554321289
local_output_nid generation:  0.03155660629272461
local_in_edges_tensor generation:  0.05126023292541504
mini_batch_src_global generation:  0.05003499984741211
r_  generation:  0.5431065559387207
local_output_nid generation:  0.046369314193725586
local_in_edges_tensor generation:  0.0588231086730957
mini_batch_src_global generation:  0.061670541763305664
r_  generation:  0.5514791011810303
----------------------check_connections_block total spend ----------------------------- 1.6687698364257812
generate_one_block  0.7202723026275635
generate_one_block  0.7112233638763428
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.027965784072875977
gen group dst list time:  0.012343168258666992
time for parepare:  0.018966197967529297
local_output_nid generation:  0.032624006271362305
local_in_edges_tensor generation:  0.0430598258972168
mini_batch_src_global generation:  0.04603123664855957
r_  generation:  0.5226254463195801
local_output_nid generation:  0.03870368003845215
local_in_edges_tensor generation:  0.04750370979309082
mini_batch_src_global generation:  0.057206153869628906
r_  generation:  0.5241844654083252
----------------------check_connections_block total spend ----------------------------- 1.5775384902954102
generate_one_block  0.6471514701843262
generate_one_block  0.6546308994293213
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0010123252868652344  GigaBytes
Max Memory Allocated: 0.0010123252868652344  GigaBytes

connection checking time:  4.769097805023193
block generation total time  4.037718772888184
average batch blocks generation time:  2.018859386444092
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2205810546875 GB
    Memory Allocated: 0.12074565887451172  GigaBytes
Max Memory Allocated: 0.12074565887451172  GigaBytes

torch.Size([167415, 128])
torch.Size([166695, 64])
torch.Size([162893, 64])
Traceback (most recent call last):
  File "pseudo_mini_batch_range_arxiv_sage.py", line 435, in <module>
    main()
  File "pseudo_mini_batch_range_arxiv_sage.py", line 431, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_arxiv_sage.py", line 251, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 182, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.62 GiB total capacity; 22.37 GiB already allocated; 10.44 MiB free; 22.41 GiB reserved in total by PyTorch)
