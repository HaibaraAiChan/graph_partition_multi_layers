Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1648486797.0549269
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.002379894256591797  GigaBytes
Max Memory Allocated: 0.002379894256591797  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.023508787155151367
random selection method range initialization spend 0.006197452545166016
time for parepare:  0.018836498260498047
local_output_nid generation:  0.008208513259887695
local_in_edges_tensor generation:  0.007858037948608398
mini_batch_src_global generation:  0.006608247756958008
r_  generation:  0.08279633522033691
local_output_nid generation:  0.01162862777709961
local_in_edges_tensor generation:  0.0059735774993896484
mini_batch_src_global generation:  0.008514165878295898
r_  generation:  0.08776521682739258
local_output_nid generation:  0.011701107025146484
local_in_edges_tensor generation:  0.00601959228515625
mini_batch_src_global generation:  0.006588935852050781
r_  generation:  0.08863115310668945
local_output_nid generation:  0.011750936508178711
local_in_edges_tensor generation:  0.00607752799987793
mini_batch_src_global generation:  0.007422208786010742
r_  generation:  0.09166193008422852
----------------------check_connections_block total spend ----------------------------- 0.550177812576294
generate_one_block  0.10064435005187988
generate_one_block  0.10045504570007324
generate_one_block  0.10206818580627441
generate_one_block  0.10340213775634766
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.039843082427978516
gen group dst list time:  0.011425018310546875
time for parepare:  0.019474029541015625
local_output_nid generation:  0.019011974334716797
local_in_edges_tensor generation:  0.04109644889831543
mini_batch_src_global generation:  0.04264330863952637
r_  generation:  0.406177282333374
local_output_nid generation:  0.02626967430114746
local_in_edges_tensor generation:  0.038829803466796875
mini_batch_src_global generation:  0.047997474670410156
r_  generation:  0.4130237102508545
local_output_nid generation:  0.026636123657226562
local_in_edges_tensor generation:  0.036139488220214844
mini_batch_src_global generation:  0.04884457588195801
r_  generation:  0.4284980297088623
local_output_nid generation:  0.02648782730102539
local_in_edges_tensor generation:  0.0324552059173584
mini_batch_src_global generation:  0.04993462562561035
r_  generation:  0.4265024662017822
----------------------check_connections_block total spend ----------------------------- 2.4980907440185547
generate_one_block  0.5574426651000977
generate_one_block  0.5306975841522217
generate_one_block  0.5509026050567627
generate_one_block  0.5483169555664062
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.02819991111755371
gen group dst list time:  0.020869970321655273
time for parepare:  0.019046783447265625
local_output_nid generation:  0.02939152717590332
local_in_edges_tensor generation:  0.04524564743041992
mini_batch_src_global generation:  0.04853010177612305
r_  generation:  0.5273079872131348
local_output_nid generation:  0.03805041313171387
local_in_edges_tensor generation:  0.05777788162231445
mini_batch_src_global generation:  0.06068587303161621
r_  generation:  0.5337808132171631
local_output_nid generation:  0.0381624698638916
local_in_edges_tensor generation:  0.045813798904418945
mini_batch_src_global generation:  0.059796810150146484
r_  generation:  0.5432353019714355
local_output_nid generation:  0.03838777542114258
local_in_edges_tensor generation:  0.045104026794433594
mini_batch_src_global generation:  0.0556485652923584
r_  generation:  0.5491378307342529
----------------------check_connections_block total spend ----------------------------- 3.2082574367523193
generate_one_block  0.6856691837310791
generate_one_block  0.6968863010406494
generate_one_block  0.6917564868927002
generate_one_block  0.6783561706542969
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.025503158569335938
gen group dst list time:  0.023587465286254883
time for parepare:  0.018666744232177734
local_output_nid generation:  0.032256126403808594
local_in_edges_tensor generation:  0.04139995574951172
mini_batch_src_global generation:  0.044983625411987305
r_  generation:  0.5026235580444336
local_output_nid generation:  0.03853178024291992
local_in_edges_tensor generation:  0.0414273738861084
mini_batch_src_global generation:  0.05716753005981445
r_  generation:  0.5041892528533936
local_output_nid generation:  0.03853416442871094
local_in_edges_tensor generation:  0.03840756416320801
mini_batch_src_global generation:  0.05763554573059082
r_  generation:  0.5062777996063232
local_output_nid generation:  0.03845787048339844
local_in_edges_tensor generation:  0.038984060287475586
mini_batch_src_global generation:  0.06007671356201172
r_  generation:  0.5122981071472168
----------------------check_connections_block total spend ----------------------------- 3.038146495819092
generate_one_block  0.6569132804870605
generate_one_block  0.6405694484710693
generate_one_block  0.6339218616485596
generate_one_block  0.6391603946685791
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.002379894256591797  GigaBytes
Max Memory Allocated: 0.002379894256591797  GigaBytes

connection checking time:  8.744494676589966
block generation total time  7.510592937469482
average batch blocks generation time:  1.8776482343673706
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2049560546875 GB
    Memory Allocated: 0.11826562881469727  GigaBytes
Max Memory Allocated: 0.11826562881469727  GigaBytes

torch.Size([166673, 128])
torch.Size([164777, 128])
Traceback (most recent call last):
  File "pseudo_mini_batch_range_arxiv_sage.py", line 435, in <module>
    main()
  File "pseudo_mini_batch_range_arxiv_sage.py", line 431, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_arxiv_sage.py", line 251, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 182, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.62 GiB total capacity; 22.37 GiB already allocated; 6.44 MiB free; 22.42 GiB reserved in total by PyTorch)
