Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1648503610.4492524
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0272216796875 GB
    Memory Allocated: 0.010137557983398438  GigaBytes
Max Memory Allocated: 0.010137557983398438  GigaBytes

The real block id is  4
get_global_graph_edges_ids_block function  spend 0.025278806686401367
random selection method range initialization spend 0.006367206573486328
time for parepare:  0.018595457077026367
local_output_nid generation:  0.016257524490356445
local_in_edges_tensor generation:  0.01580953598022461
mini_batch_src_global generation:  0.014043807983398438
r_  generation:  0.16950726509094238
local_output_nid generation:  0.021831274032592773
local_in_edges_tensor generation:  0.01586151123046875
mini_batch_src_global generation:  0.017212390899658203
r_  generation:  0.1768817901611328
----------------------check_connections_block total spend ----------------------------- 0.54422926902771
generate_one_block  0.20341229438781738
generate_one_block  0.19962406158447266
The real block id is  3
get_global_graph_edges_ids_block function  spend 0.04134988784790039
gen group dst list time:  0.007599353790283203
time for parepare:  0.019864559173583984
local_output_nid generation:  0.026427268981933594
local_in_edges_tensor generation:  0.05446505546569824
mini_batch_src_global generation:  0.046506643295288086
r_  generation:  0.4972677230834961
local_output_nid generation:  0.036548614501953125
local_in_edges_tensor generation:  0.05011701583862305
mini_batch_src_global generation:  0.056436777114868164
r_  generation:  0.5088577270507812
----------------------check_connections_block total spend ----------------------------- 1.5308480262756348
generate_one_block  0.6462523937225342
generate_one_block  0.6499645709991455
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.03713488578796387
gen group dst list time:  0.011794090270996094
time for parepare:  0.019709110260009766
local_output_nid generation:  0.031252145767211914
local_in_edges_tensor generation:  0.05366325378417969
mini_batch_src_global generation:  0.05086660385131836
r_  generation:  0.5634663105010986
local_output_nid generation:  0.04191851615905762
local_in_edges_tensor generation:  0.060194969177246094
mini_batch_src_global generation:  0.06332993507385254
r_  generation:  0.5667626857757568
----------------------check_connections_block total spend ----------------------------- 1.710230827331543
generate_one_block  0.7334845066070557
generate_one_block  0.7177152633666992
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.030466318130493164
gen group dst list time:  0.012534856796264648
time for parepare:  0.01867389678955078
local_output_nid generation:  0.03162550926208496
local_in_edges_tensor generation:  0.04511666297912598
mini_batch_src_global generation:  0.049860239028930664
r_  generation:  0.5525510311126709
local_output_nid generation:  0.0383448600769043
local_in_edges_tensor generation:  0.057770490646362305
mini_batch_src_global generation:  0.0626978874206543
r_  generation:  0.5559861660003662
----------------------check_connections_block total spend ----------------------------- 1.6771535873413086
generate_one_block  0.6927926540374756
generate_one_block  0.7063882350921631
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.027129173278808594
gen group dst list time:  0.012511491775512695
time for parepare:  0.019394874572753906
local_output_nid generation:  0.03269147872924805
local_in_edges_tensor generation:  0.04481053352355957
mini_batch_src_global generation:  0.04536771774291992
r_  generation:  0.5119774341583252
local_output_nid generation:  0.04386639595031738
local_in_edges_tensor generation:  0.03577589988708496
mini_batch_src_global generation:  0.05877208709716797
r_  generation:  0.5176594257354736
----------------------check_connections_block total spend ----------------------------- 1.563321590423584
generate_one_block  0.637164831161499
generate_one_block  0.652644157409668
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0272216796875 GB
    Memory Allocated: 0.010137557983398438  GigaBytes
Max Memory Allocated: 0.010137557983398438  GigaBytes

connection checking time:  6.48155403137207
block generation total time  5.43640661239624
average batch blocks generation time:  2.71820330619812
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2303466796875 GB
    Memory Allocated: 0.14317560195922852  GigaBytes
Max Memory Allocated: 0.14317560195922852  GigaBytes

torch.Size([167821, 128])
torch.Size([167573, 256])
Traceback (most recent call last):
  File "pseudo_mini_batch_range_arxiv_sage.py", line 435, in <module>
    main()
  File "pseudo_mini_batch_range_arxiv_sage.py", line 431, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_arxiv_sage.py", line 251, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 182, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 23.62 GiB total capacity; 21.89 GiB already allocated; 32.44 MiB free; 22.39 GiB reserved in total by PyTorch)
