Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1648804644.1183133
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0017633438110351562  GigaBytes
Max Memory Allocated: 0.0017633438110351562  GigaBytes

{'VmPeak': 20917.4375, 'VmSize': 20908.67578125, 'VmHWM': 3746.3046875, 'VmRSS': 3746.3046875}
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.024793148040771484
global_2_local 0.027069568634033203
---------------------------- variant graph partition start---------------------
range_init for graph_partition spend:  0.01775503158569336
before graph partition 
		134458, 134446, 

{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-

-------------------------------------------------------------  compare batch pair  (0,1)
				 list len:
				45471, 45470, 


	preparing two sides time :  0.10986161231994629
	Initialize BitList time :  0.006639242172241211
	getRedundancyCost: time   7.3909759521484375e-06

					length of partitions 134458, 134446

	before terminate 1 the average redundancy rate is:  1.7100087120754455
	--------------------------------------------------------------------------------
	 walk terminate 1 start-------
						 current side  0
			 redundancy will reduce  0.2524848492556582
			 the number of node to move is : 27433
			 --group redundancy rate update  step :0  side 0
			 redundancy rate (ration_mean, ratio_A, ratio_B): 1.4575238628197873,  1.014708781390498,  1.9003389442490763
						 current side  1
			 redundancy will reduce  0.24231016260421123
			 the number of node to move is : 5446
			 --group redundancy rate update  step :1  side 1
			 redundancy rate (ration_mean, ratio_A, ratio_B): 1.4676985494712342,  1.1032794286913445,  1.832117670251124
						 current side  0
			 redundancy will reduce  0.27242723509249434
			 the number of node to move is : 2059
			 --group redundancy rate update  step :2  side 0
			 redundancy rate (ration_mean, ratio_A, ratio_B): 1.4375814769829511,  1.0282538329952369,  1.8469091209706652
	walk terminate 1 spend time 140.78379726409912
				 improvement:  True
	 walk terminate 1 start-------
						 current side  1
			 redundancy will reduce  0.26432564084627974
			 the number of node to move is : 4686
			 --group redundancy rate update  step :0  side 1
			 redundancy rate (ration_mean, ratio_A, ratio_B): 1.4456830712291657,  1.1138356660922208,  1.7775304763661106
						 current side  0
			 redundancy will reduce  0.29858889814502754
			 the number of node to move is : 2182
			 --group redundancy rate update  step :1  side 0
			 redundancy rate (ration_mean, ratio_A, ratio_B): 1.411419813930418,  1.028126649412094,  1.794712978448742
						 current side  1
			 redundancy will reduce  0.302563385118249
			 the number of node to move is : 1099
			 --group redundancy rate update  step :2  side 1
			 redundancy rate (ration_mean, ratio_A, ratio_B): 1.4074453269571965,  1.040654232351688,  1.7742364215627047
	walk terminate 1 spend time 147.90835165977478
				 improvement:  True
0
side is 1
	 walk step 1  partition 
		81823, 139502, 


	--------------------------------------------------end of batch 0
after graph partition
graph partition algorithm spend time 289.3037168979645
partition_len_list
[81823, 139502]
range_init_graph_partition selection method range initialization spend 289.3723244667053
time for parepare:  0.015885114669799805
local_output_nid generation:  0.006446123123168945
local_in_edges_tensor generation:  0.022533416748046875
mini_batch_src_global generation:  0.004281520843505859
r_  generation:  0.06944012641906738
local_output_nid generation:  0.009308815002441406
local_in_edges_tensor generation:  0.013983964920043945
mini_batch_src_global generation:  0.0255281925201416
r_  generation:  0.2545175552368164
----------------------check_connections_block total spend ----------------------------- 0.5107836723327637
generate_one_block  0.09669303894042969
generate_one_block  0.32160329818725586
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.05969738960266113
gen group dst list time:  0.005585193634033203
time for parepare:  0.022468090057373047
local_output_nid generation:  0.018898487091064453
local_in_edges_tensor generation:  0.03990340232849121
mini_batch_src_global generation:  0.034777164459228516
r_  generation:  0.32742881774902344
local_output_nid generation:  0.0304567813873291
local_in_edges_tensor generation:  0.043814659118652344
mini_batch_src_global generation:  0.058196306228637695
r_  generation:  0.5311594009399414
----------------------check_connections_block total spend ----------------------------- 1.3095405101776123
generate_one_block  0.4412832260131836
generate_one_block  0.6728205680847168
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.04257488250732422
gen group dst list time:  0.010965585708618164
time for parepare:  0.0206143856048584
local_output_nid generation:  0.03525733947753906
local_in_edges_tensor generation:  0.047616004943847656
mini_batch_src_global generation:  0.04920697212219238
r_  generation:  0.5062649250030518
local_output_nid generation:  0.03862357139587402
local_in_edges_tensor generation:  0.04685640335083008
mini_batch_src_global generation:  0.05706286430358887
r_  generation:  0.5338938236236572
----------------------check_connections_block total spend ----------------------------- 1.5953352451324463
generate_one_block  0.65427565574646
generate_one_block  0.6965930461883545
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0017633438110351562  GigaBytes
Max Memory Allocated: 0.0017633438110351562  GigaBytes

{'VmPeak': 21421.97265625, 'VmSize': 21359.796875, 'VmHWM': 4464.46875, 'VmRSS': 4402.48828125}
connection checking time:  2.9048757553100586
block generation total time  2.464972496032715
average batch blocks generation time:  1.2324862480163574
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.1815185546875 GB
    Memory Allocated: 0.10087966918945312  GigaBytes
Max Memory Allocated: 0.10087966918945312  GigaBytes

{'VmPeak': 21567.15625, 'VmSize': 21519.796875, 'VmHWM': 4479.20703125, 'VmRSS': 4464.84375}
torch.Size([162535, 128])
torch.Size([147115, 128])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.1444091796875 GB
    Memory Allocated: 20.698391437530518  GigaBytes
Max Memory Allocated: 20.798255920410156  GigaBytes

{'VmPeak': 49250.5859375, 'VmSize': 49218.58984375, 'VmHWM': 4786.8671875, 'VmRSS': 4786.8671875}
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 23.3924560546875 GB
    Memory Allocated: 0.1157984733581543  GigaBytes
Max Memory Allocated: 20.798255920410156  GigaBytes

{'VmPeak': 50612.19140625, 'VmSize': 50549.06640625, 'VmHWM': 4870.5546875, 'VmRSS': 4808.015625}
torch.Size([166159, 128])
torch.Size([161881, 128])
Traceback (most recent call last):
  File "pseudo_mini_batch_arxiv_sage.py", line 440, in <module>
    main()
  File "pseudo_mini_batch_arxiv_sage.py", line 436, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_arxiv_sage.py", line 253, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 182, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 23.62 GiB total capacity; 22.32 GiB already allocated; 10.44 MiB free; 22.40 GiB reserved in total by PyTorch)
