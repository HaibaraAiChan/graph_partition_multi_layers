Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1647803055.0675614
ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0213623046875 GB
    Memory Allocated: 0.005230903625488281  GigaBytes
Max Memory Allocated: 0.005230903625488281  GigaBytes

The real block id is  2
get_global_graph_edges_ids_block function  spend 0.027495145797729492
range selection method range initialization spend 0.013875961303710938
time for parepare:  0.018018007278442383
local_output_nid generation:  0.00532221794128418
local_in_edges_tensor generation:  0.006253957748413086
mini_batch_src_global generation:  0.007549285888671875
r_  generation:  0.09119009971618652
local_output_nid generation:  0.006036996841430664
local_in_edges_tensor generation:  0.003233671188354492
mini_batch_src_global generation:  0.009972572326660156
r_  generation:  0.09888672828674316
local_output_nid generation:  0.006108760833740234
local_in_edges_tensor generation:  0.003214120864868164
mini_batch_src_global generation:  0.007781028747558594
r_  generation:  0.10256481170654297
local_output_nid generation:  0.00608062744140625
local_in_edges_tensor generation:  0.003318309783935547
mini_batch_src_global generation:  0.008365154266357422
r_  generation:  0.10399079322814941
----------------------check_connections_block total spend ----------------------------- 0.5676116943359375
generate_one_block  0.11397290229797363
generate_one_block  0.11870622634887695
generate_one_block  0.11612653732299805
generate_one_block  0.1172018051147461
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.04288458824157715
gen group dst list time:  0.012284994125366211
time for parepare:  0.019567251205444336
local_output_nid generation:  0.015278100967407227
local_in_edges_tensor generation:  0.0404353141784668
mini_batch_src_global generation:  0.04967164993286133
r_  generation:  0.4640817642211914
local_output_nid generation:  0.02430582046508789
local_in_edges_tensor generation:  0.041993141174316406
mini_batch_src_global generation:  0.06039237976074219
r_  generation:  0.47883105278015137
local_output_nid generation:  0.025834083557128906
local_in_edges_tensor generation:  0.0305941104888916
mini_batch_src_global generation:  0.056849002838134766
r_  generation:  0.48416757583618164
local_output_nid generation:  0.02579665184020996
local_in_edges_tensor generation:  0.029975175857543945
mini_batch_src_global generation:  0.05798459053039551
r_  generation:  0.4899749755859375
----------------------check_connections_block total spend ----------------------------- 2.801389217376709
generate_one_block  0.6491327285766602
generate_one_block  0.6495370864868164
generate_one_block  0.6251723766326904
generate_one_block  0.6425786018371582
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.03143453598022461
gen group dst list time:  0.021955013275146484
time for parepare:  0.019051313400268555
local_output_nid generation:  0.024450302124023438
local_in_edges_tensor generation:  0.0355679988861084
mini_batch_src_global generation:  0.04496288299560547
r_  generation:  0.49529266357421875
local_output_nid generation:  0.033240556716918945
local_in_edges_tensor generation:  0.04662299156188965
mini_batch_src_global generation:  0.05750894546508789
r_  generation:  0.5055301189422607
local_output_nid generation:  0.03420686721801758
local_in_edges_tensor generation:  0.03791999816894531
mini_batch_src_global generation:  0.060831546783447266
r_  generation:  0.5050008296966553
local_output_nid generation:  0.03480076789855957
local_in_edges_tensor generation:  0.03743267059326172
mini_batch_src_global generation:  0.0568692684173584
r_  generation:  0.5083048343658447
----------------------check_connections_block total spend ----------------------------- 2.9853317737579346
generate_one_block  0.6307663917541504
generate_one_block  0.6417059898376465
generate_one_block  0.6463727951049805
generate_one_block  0.6453580856323242
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0213623046875 GB
    Memory Allocated: 0.005230903625488281  GigaBytes
Max Memory Allocated: 0.005230903625488281  GigaBytes

connection checking time:  5.7867209911346436
block generation total time  5.130624055862427
average batch blocks generation time:  1.2826560139656067
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2069091796875 GB
    Memory Allocated: 0.10929298400878906  GigaBytes
Max Memory Allocated: 0.10929298400878906  GigaBytes

Traceback (most recent call last):
  File "pseudo_mini_batch_range_arxiv_sage.py", line 433, in <module>
    main()
  File "pseudo_mini_batch_range_arxiv_sage.py", line 429, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_arxiv_sage.py", line 251, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 53, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.62 GiB total capacity; 21.99 GiB already allocated; 14.44 MiB free; 22.41 GiB reserved in total by PyTorch)
