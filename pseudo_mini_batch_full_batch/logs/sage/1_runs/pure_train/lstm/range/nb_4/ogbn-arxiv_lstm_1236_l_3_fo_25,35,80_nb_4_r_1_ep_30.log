Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1647800108.0756934
ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0213623046875 GB
    Memory Allocated: 0.005230903625488281  GigaBytes
Max Memory Allocated: 0.005230903625488281  GigaBytes

The real block id is  2
get_global_graph_edges_ids_block function  spend 0.027105093002319336
range selection method range initialization spend 0.017407655715942383
time for parepare:  0.018457651138305664
local_output_nid generation:  0.005355358123779297
local_in_edges_tensor generation:  0.0061473846435546875
mini_batch_src_global generation:  0.007622957229614258
r_  generation:  0.09079241752624512
local_output_nid generation:  0.006076812744140625
local_in_edges_tensor generation:  0.003184080123901367
mini_batch_src_global generation:  0.009917020797729492
r_  generation:  0.09935760498046875
local_output_nid generation:  0.006067752838134766
local_in_edges_tensor generation:  0.003146648406982422
mini_batch_src_global generation:  0.007635831832885742
r_  generation:  0.10328912734985352
local_output_nid generation:  0.006134986877441406
local_in_edges_tensor generation:  0.003237485885620117
mini_batch_src_global generation:  0.008225440979003906
r_  generation:  0.10340523719787598
----------------------check_connections_block total spend ----------------------------- 0.567188024520874
generate_one_block  0.11323308944702148
generate_one_block  0.11759114265441895
generate_one_block  0.11561751365661621
generate_one_block  0.1161355972290039
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.03702092170715332
gen group dst list time:  0.012166500091552734
time for parepare:  0.01908087730407715
local_output_nid generation:  0.015185356140136719
local_in_edges_tensor generation:  0.03291630744934082
mini_batch_src_global generation:  0.04232597351074219
r_  generation:  0.42471885681152344
local_output_nid generation:  0.02257251739501953
local_in_edges_tensor generation:  0.039016008377075195
mini_batch_src_global generation:  0.05413341522216797
r_  generation:  0.45127296447753906
local_output_nid generation:  0.023511409759521484
local_in_edges_tensor generation:  0.03170895576477051
mini_batch_src_global generation:  0.05281996726989746
r_  generation:  0.4637324810028076
local_output_nid generation:  0.025004148483276367
local_in_edges_tensor generation:  0.03976297378540039
mini_batch_src_global generation:  0.06386375427246094
r_  generation:  0.4406311511993408
----------------------check_connections_block total spend ----------------------------- 2.6171457767486572
generate_one_block  0.5887115001678467
generate_one_block  0.5681343078613281
generate_one_block  0.566946268081665
generate_one_block  0.5844027996063232
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.03995776176452637
gen group dst list time:  0.023380041122436523
time for parepare:  0.020646095275878906
local_output_nid generation:  0.024390459060668945
local_in_edges_tensor generation:  0.05459189414978027
mini_batch_src_global generation:  0.04853463172912598
r_  generation:  0.5168471336364746
local_output_nid generation:  0.0359189510345459
local_in_edges_tensor generation:  0.05542349815368652
mini_batch_src_global generation:  0.05702948570251465
r_  generation:  0.5047760009765625
local_output_nid generation:  0.036785125732421875
local_in_edges_tensor generation:  0.03923368453979492
mini_batch_src_global generation:  0.05464434623718262
r_  generation:  0.5084316730499268
local_output_nid generation:  0.0352940559387207
local_in_edges_tensor generation:  0.04283022880554199
mini_batch_src_global generation:  0.06235384941101074
r_  generation:  0.5218405723571777
----------------------check_connections_block total spend ----------------------------- 3.0540521144866943
generate_one_block  0.6608066558837891
generate_one_block  0.6541397571563721
generate_one_block  0.6342253684997559
generate_one_block  0.6377294063568115
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0213623046875 GB
    Memory Allocated: 0.005230903625488281  GigaBytes
Max Memory Allocated: 0.005230903625488281  GigaBytes

connection checking time:  5.671197891235352
block generation total time  4.895096063613892
average batch blocks generation time:  1.223774015903473
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2069091796875 GB
    Memory Allocated: 0.10738658905029297  GigaBytes
Max Memory Allocated: 0.10738658905029297  GigaBytes

Traceback (most recent call last):
  File "pseudo_mini_batch_range_arxiv_sage.py", line 433, in <module>
    main()
  File "pseudo_mini_batch_range_arxiv_sage.py", line 429, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_arxiv_sage.py", line 251, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 53, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.62 GiB total capacity; 22.00 GiB already allocated; 18.44 MiB free; 22.41 GiB reserved in total by PyTorch)
