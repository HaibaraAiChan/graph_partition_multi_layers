Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1647806577.8621686
ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0213623046875 GB
    Memory Allocated: 0.005230903625488281  GigaBytes
Max Memory Allocated: 0.005230903625488281  GigaBytes

The real block id is  2
get_global_graph_edges_ids_block function  spend 0.027203083038330078
range selection method range initialization spend 0.013475179672241211
time for parepare:  0.01804184913635254
local_output_nid generation:  0.005331516265869141
local_in_edges_tensor generation:  0.006566047668457031
mini_batch_src_global generation:  0.007394075393676758
r_  generation:  0.09029150009155273
local_output_nid generation:  0.006038188934326172
local_in_edges_tensor generation:  0.003155946731567383
mini_batch_src_global generation:  0.009788751602172852
r_  generation:  0.0973808765411377
local_output_nid generation:  0.0060977935791015625
local_in_edges_tensor generation:  0.0032744407653808594
mini_batch_src_global generation:  0.007762908935546875
r_  generation:  0.1001431941986084
local_output_nid generation:  0.00611424446105957
local_in_edges_tensor generation:  0.003223419189453125
mini_batch_src_global generation:  0.00786447525024414
r_  generation:  0.10259485244750977
----------------------check_connections_block total spend ----------------------------- 0.5590119361877441
generate_one_block  0.1145620346069336
generate_one_block  0.11707067489624023
generate_one_block  0.11600899696350098
generate_one_block  0.11574864387512207
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.04613637924194336
gen group dst list time:  0.01198124885559082
time for parepare:  0.01910400390625
local_output_nid generation:  0.014461040496826172
local_in_edges_tensor generation:  0.037038326263427734
mini_batch_src_global generation:  0.04853034019470215
r_  generation:  0.4622077941894531
local_output_nid generation:  0.022238731384277344
local_in_edges_tensor generation:  0.04373788833618164
mini_batch_src_global generation:  0.056502580642700195
r_  generation:  0.4794461727142334
local_output_nid generation:  0.022783994674682617
local_in_edges_tensor generation:  0.040146827697753906
mini_batch_src_global generation:  0.05567669868469238
r_  generation:  0.4848341941833496
local_output_nid generation:  0.023348331451416016
local_in_edges_tensor generation:  0.02749180793762207
mini_batch_src_global generation:  0.05829119682312012
r_  generation:  0.48662710189819336
----------------------check_connections_block total spend ----------------------------- 2.786555290222168
generate_one_block  0.6489267349243164
generate_one_block  0.6375181674957275
generate_one_block  0.630516529083252
generate_one_block  0.6363966464996338
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.037981510162353516
gen group dst list time:  0.021418094635009766
time for parepare:  0.018742799758911133
local_output_nid generation:  0.023500919342041016
local_in_edges_tensor generation:  0.043237924575805664
mini_batch_src_global generation:  0.05404925346374512
r_  generation:  0.5629401206970215
local_output_nid generation:  0.03320741653442383
local_in_edges_tensor generation:  0.05552220344543457
mini_batch_src_global generation:  0.06657004356384277
r_  generation:  0.5768318176269531
local_output_nid generation:  0.034064292907714844
local_in_edges_tensor generation:  0.04255032539367676
mini_batch_src_global generation:  0.06969833374023438
r_  generation:  0.5729079246520996
local_output_nid generation:  0.033637285232543945
local_in_edges_tensor generation:  0.047026634216308594
mini_batch_src_global generation:  0.0648193359375
r_  generation:  0.5838346481323242
----------------------check_connections_block total spend ----------------------------- 3.377678394317627
generate_one_block  0.7431175708770752
generate_one_block  0.7503323554992676
generate_one_block  0.7496418952941895
generate_one_block  0.7430300712585449
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0213623046875 GB
    Memory Allocated: 0.005230903625488281  GigaBytes
Max Memory Allocated: 0.005230903625488281  GigaBytes

connection checking time:  6.164233684539795
block generation total time  5.539479970932007
average batch blocks generation time:  1.3848699927330017
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2069091796875 GB
    Memory Allocated: 0.11161422729492188  GigaBytes
Max Memory Allocated: 0.11161422729492188  GigaBytes

Traceback (most recent call last):
  File "pseudo_mini_batch_range_arxiv_sage.py", line 433, in <module>
    main()
  File "pseudo_mini_batch_range_arxiv_sage.py", line 429, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_arxiv_sage.py", line 251, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 53, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 23.62 GiB total capacity; 21.96 GiB already allocated; 10.44 MiB free; 22.41 GiB reserved in total by PyTorch)
