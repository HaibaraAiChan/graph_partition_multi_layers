Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1647783357.2724829
ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0213623046875 GB
    Memory Allocated: 0.005230903625488281  GigaBytes
Max Memory Allocated: 0.005230903625488281  GigaBytes

The real block id is  2
get_global_graph_edges_ids_block function  spend 0.023371458053588867
random selection method range initialization spend 0.0057888031005859375
time for parepare:  0.019063472747802734
local_output_nid generation:  0.008306264877319336
local_in_edges_tensor generation:  0.007882833480834961
mini_batch_src_global generation:  0.006575345993041992
r_  generation:  0.08290529251098633
local_output_nid generation:  0.011581897735595703
local_in_edges_tensor generation:  0.005893707275390625
mini_batch_src_global generation:  0.008843183517456055
r_  generation:  0.0889139175415039
local_output_nid generation:  0.01165771484375
local_in_edges_tensor generation:  0.005980968475341797
mini_batch_src_global generation:  0.006631135940551758
r_  generation:  0.08923482894897461
local_output_nid generation:  0.01172327995300293
local_in_edges_tensor generation:  0.0059680938720703125
mini_batch_src_global generation:  0.007297515869140625
r_  generation:  0.09131836891174316
----------------------check_connections_block total spend ----------------------------- 0.552077054977417
generate_one_block  0.1012725830078125
generate_one_block  0.10183477401733398
generate_one_block  0.10167551040649414
generate_one_block  0.102081298828125
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.03763771057128906
gen group dst list time:  0.01152801513671875
time for parepare:  0.01921987533569336
local_output_nid generation:  0.01969599723815918
local_in_edges_tensor generation:  0.04033708572387695
mini_batch_src_global generation:  0.04024934768676758
r_  generation:  0.3925192356109619
local_output_nid generation:  0.02754497528076172
local_in_edges_tensor generation:  0.03974556922912598
mini_batch_src_global generation:  0.046486616134643555
r_  generation:  0.40252065658569336
local_output_nid generation:  0.028000593185424805
local_in_edges_tensor generation:  0.032416343688964844
mini_batch_src_global generation:  0.04686784744262695
r_  generation:  0.40816783905029297
local_output_nid generation:  0.027812719345092773
local_in_edges_tensor generation:  0.025151491165161133
mini_batch_src_global generation:  0.04790496826171875
r_  generation:  0.41029882431030273
----------------------check_connections_block total spend ----------------------------- 2.412816047668457
generate_one_block  0.5448050498962402
generate_one_block  0.5272669792175293
generate_one_block  0.5258316993713379
generate_one_block  0.5245983600616455
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.03169965744018555
gen group dst list time:  0.021094799041748047
time for parepare:  0.018704891204833984
local_output_nid generation:  0.029243946075439453
local_in_edges_tensor generation:  0.04302406311035156
mini_batch_src_global generation:  0.04473757743835449
r_  generation:  0.4923715591430664
local_output_nid generation:  0.0363614559173584
local_in_edges_tensor generation:  0.05152297019958496
mini_batch_src_global generation:  0.055254459381103516
r_  generation:  0.5021777153015137
local_output_nid generation:  0.03621244430541992
local_in_edges_tensor generation:  0.04009389877319336
mini_batch_src_global generation:  0.05484199523925781
r_  generation:  0.5102636814117432
local_output_nid generation:  0.0363612174987793
local_in_edges_tensor generation:  0.044058799743652344
mini_batch_src_global generation:  0.05126690864562988
r_  generation:  0.5122008323669434
----------------------check_connections_block total spend ----------------------------- 3.0058536529541016
generate_one_block  0.6348059177398682
generate_one_block  0.6311297416687012
generate_one_block  0.6357746124267578
generate_one_block  0.6302728652954102
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0213623046875 GB
    Memory Allocated: 0.005230903625488281  GigaBytes
Max Memory Allocated: 0.005230903625488281  GigaBytes

connection checking time:  5.418669700622559
block generation total time  4.65448522567749
average batch blocks generation time:  1.1636213064193726
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2069091796875 GB
    Memory Allocated: 0.10628747940063477  GigaBytes
Max Memory Allocated: 0.10628747940063477  GigaBytes

Traceback (most recent call last):
  File "pseudo_mini_batch_range_arxiv_sage.py", line 433, in <module>
    main()
  File "pseudo_mini_batch_range_arxiv_sage.py", line 429, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_arxiv_sage.py", line 251, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 53, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.62 GiB total capacity; 21.97 GiB already allocated; 16.44 MiB free; 22.41 GiB reserved in total by PyTorch)
