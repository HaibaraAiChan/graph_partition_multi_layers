Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1647792407.4330826
ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0213623046875 GB
    Memory Allocated: 0.005230903625488281  GigaBytes
Max Memory Allocated: 0.005230903625488281  GigaBytes

The real block id is  2
get_global_graph_edges_ids_block function  spend 0.02711176872253418
random selection method range initialization spend 0.006188631057739258
time for parepare:  0.018275976181030273
local_output_nid generation:  0.008328676223754883
local_in_edges_tensor generation:  0.010483026504516602
mini_batch_src_global generation:  0.007174491882324219
r_  generation:  0.0906822681427002
local_output_nid generation:  0.011593341827392578
local_in_edges_tensor generation:  0.006670951843261719
mini_batch_src_global generation:  0.00936436653137207
r_  generation:  0.09719300270080566
local_output_nid generation:  0.011729717254638672
local_in_edges_tensor generation:  0.006750583648681641
mini_batch_src_global generation:  0.007338523864746094
r_  generation:  0.10112261772155762
local_output_nid generation:  0.011721611022949219
local_in_edges_tensor generation:  0.006676912307739258
mini_batch_src_global generation:  0.008054733276367188
r_  generation:  0.10114264488220215
----------------------check_connections_block total spend ----------------------------- 0.6006646156311035
generate_one_block  0.11550474166870117
generate_one_block  0.11558365821838379
generate_one_block  0.11661410331726074
generate_one_block  0.11569857597351074
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0453028678894043
gen group dst list time:  0.01129460334777832
time for parepare:  0.01898670196533203
local_output_nid generation:  0.020819902420043945
local_in_edges_tensor generation:  0.04804396629333496
mini_batch_src_global generation:  0.04862189292907715
r_  generation:  0.46982645988464355
local_output_nid generation:  0.03144979476928711
local_in_edges_tensor generation:  0.04744362831115723
mini_batch_src_global generation:  0.06670880317687988
r_  generation:  0.5016825199127197
local_output_nid generation:  0.031166553497314453
local_in_edges_tensor generation:  0.056765079498291016
mini_batch_src_global generation:  0.06335783004760742
r_  generation:  0.4866063594818115
local_output_nid generation:  0.028061628341674805
local_in_edges_tensor generation:  0.03959250450134277
mini_batch_src_global generation:  0.05642390251159668
r_  generation:  0.4875054359436035
----------------------check_connections_block total spend ----------------------------- 2.9601974487304688
generate_one_block  0.6662557125091553
generate_one_block  0.6393811702728271
generate_one_block  0.6366050243377686
generate_one_block  0.6354098320007324
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.05887317657470703
gen group dst list time:  0.021489381790161133
time for parepare:  0.0188138484954834
local_output_nid generation:  0.030757665634155273
local_in_edges_tensor generation:  0.08957648277282715
mini_batch_src_global generation:  0.0540318489074707
r_  generation:  0.5574042797088623
local_output_nid generation:  0.03807353973388672
local_in_edges_tensor generation:  0.058542728424072266
mini_batch_src_global generation:  0.06601595878601074
r_  generation:  0.5607469081878662
local_output_nid generation:  0.037865400314331055
local_in_edges_tensor generation:  0.05421185493469238
mini_batch_src_global generation:  0.06943488121032715
r_  generation:  0.5769021511077881
local_output_nid generation:  0.03795194625854492
local_in_edges_tensor generation:  0.054860830307006836
mini_batch_src_global generation:  0.06481719017028809
r_  generation:  0.6105256080627441
----------------------check_connections_block total spend ----------------------------- 3.497314453125
generate_one_block  0.7493972778320312
generate_one_block  0.7759842872619629
generate_one_block  0.7524588108062744
generate_one_block  0.761627197265625
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0213623046875 GB
    Memory Allocated: 0.005230903625488281  GigaBytes
Max Memory Allocated: 0.005230903625488281  GigaBytes

connection checking time:  6.457511901855469
block generation total time  5.617119312286377
average batch blocks generation time:  1.4042798280715942
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2069091796875 GB
    Memory Allocated: 0.11154747009277344  GigaBytes
Max Memory Allocated: 0.11154747009277344  GigaBytes

Traceback (most recent call last):
  File "pseudo_mini_batch_range_arxiv_sage.py", line 433, in <module>
    main()
  File "pseudo_mini_batch_range_arxiv_sage.py", line 429, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_arxiv_sage.py", line 251, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 53, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 23.62 GiB total capacity; 21.93 GiB already allocated; 12.44 MiB free; 22.41 GiB reserved in total by PyTorch)
