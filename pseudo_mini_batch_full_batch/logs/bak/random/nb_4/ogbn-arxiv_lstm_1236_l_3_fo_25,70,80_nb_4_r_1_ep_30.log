Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1647788867.8295505
ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0213623046875 GB
    Memory Allocated: 0.005230903625488281  GigaBytes
Max Memory Allocated: 0.005230903625488281  GigaBytes

The real block id is  2
get_global_graph_edges_ids_block function  spend 0.02787923812866211
random selection method range initialization spend 0.006400585174560547
time for parepare:  0.018656492233276367
local_output_nid generation:  0.008429765701293945
local_in_edges_tensor generation:  0.00950932502746582
mini_batch_src_global generation:  0.00742030143737793
r_  generation:  0.09059762954711914
local_output_nid generation:  0.011617898941040039
local_in_edges_tensor generation:  0.006178140640258789
mini_batch_src_global generation:  0.009754419326782227
r_  generation:  0.09610557556152344
local_output_nid generation:  0.011890411376953125
local_in_edges_tensor generation:  0.0067844390869140625
mini_batch_src_global generation:  0.007836103439331055
r_  generation:  0.10279202461242676
local_output_nid generation:  0.011754035949707031
local_in_edges_tensor generation:  0.006314516067504883
mini_batch_src_global generation:  0.00862741470336914
r_  generation:  0.1040952205657959
----------------------check_connections_block total spend ----------------------------- 0.6088519096374512
generate_one_block  0.11682438850402832
generate_one_block  0.11642694473266602
generate_one_block  0.11585402488708496
generate_one_block  0.11572098731994629
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.04471588134765625
gen group dst list time:  0.011762619018554688
time for parepare:  0.019382476806640625
local_output_nid generation:  0.02049875259399414
local_in_edges_tensor generation:  0.04869532585144043
mini_batch_src_global generation:  0.04626774787902832
r_  generation:  0.47522664070129395
local_output_nid generation:  0.02635979652404785
local_in_edges_tensor generation:  0.04829144477844238
mini_batch_src_global generation:  0.056754112243652344
r_  generation:  0.4817938804626465
local_output_nid generation:  0.02654290199279785
local_in_edges_tensor generation:  0.03898811340332031
mini_batch_src_global generation:  0.060401201248168945
r_  generation:  0.49401235580444336
local_output_nid generation:  0.026408910751342773
local_in_edges_tensor generation:  0.04105544090270996
mini_batch_src_global generation:  0.06118130683898926
r_  generation:  0.4914863109588623
----------------------check_connections_block total spend ----------------------------- 2.8940815925598145
generate_one_block  0.6832165718078613
generate_one_block  0.6309294700622559
generate_one_block  0.6405150890350342
generate_one_block  0.6452233791351318
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.028913497924804688
gen group dst list time:  0.021349191665649414
time for parepare:  0.019448518753051758
local_output_nid generation:  0.030025482177734375
local_in_edges_tensor generation:  0.04616212844848633
mini_batch_src_global generation:  0.04656624794006348
r_  generation:  0.5042734146118164
local_output_nid generation:  0.03776884078979492
local_in_edges_tensor generation:  0.04599928855895996
mini_batch_src_global generation:  0.05879521369934082
r_  generation:  0.5080380439758301
local_output_nid generation:  0.03775215148925781
local_in_edges_tensor generation:  0.04770541191101074
mini_batch_src_global generation:  0.061231136322021484
r_  generation:  0.513885498046875
local_output_nid generation:  0.03800177574157715
local_in_edges_tensor generation:  0.05347108840942383
mini_batch_src_global generation:  0.05782008171081543
r_  generation:  0.5168025493621826
----------------------check_connections_block total spend ----------------------------- 3.0912625789642334
generate_one_block  0.6342747211456299
generate_one_block  0.6476609706878662
generate_one_block  0.6493275165557861
generate_one_block  0.651019811630249
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0213623046875 GB
    Memory Allocated: 0.005230903625488281  GigaBytes
Max Memory Allocated: 0.005230903625488281  GigaBytes

connection checking time:  5.985344171524048
block generation total time  5.1821675300598145
average batch blocks generation time:  1.2955418825149536
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2069091796875 GB
    Memory Allocated: 0.10931777954101562  GigaBytes
Max Memory Allocated: 0.10931777954101562  GigaBytes

Traceback (most recent call last):
  File "pseudo_mini_batch_range_arxiv_sage.py", line 433, in <module>
    main()
  File "pseudo_mini_batch_range_arxiv_sage.py", line 429, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_arxiv_sage.py", line 251, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_arxiv.py", line 53, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 173, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 582, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.62 GiB total capacity; 22.02 GiB already allocated; 20.44 MiB free; 22.40 GiB reserved in total by PyTorch)
