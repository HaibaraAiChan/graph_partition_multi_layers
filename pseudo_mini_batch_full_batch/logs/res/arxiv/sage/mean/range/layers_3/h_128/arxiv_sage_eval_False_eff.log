computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |     pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |         25,70,80 |        2 batches |        4 batches |   8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |         25,70,80 |         25,70,80 |    25,70,80 |         25,70,80 |         25,70,80 |         25,70,80 |
+=================================================+==================+==================+==================+=============+==================+==================+==================+
| final layer output nodes/pure train time        |      1.64793e+06 |      1.56498e+06 |      1.39743e+06 | 1.46281e+06 | 783483           | 411093           | 185923           |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      8.97875e+06 |      1.62062e+07 |      2.64506e+07 | 4.91094e+07 |      4.58098e+07 |      4.11938e+07 |      3.11958e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.0551851   |      0.05811     |      0.0650773   | 0.0621688   |      0.116073    |      0.221218    |      0.489133    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average number of nodes for computation         | 495493           | 941740           |      1.72133e+06 | 3.05307e+06 |      5.31726e+06 |      9.1128e+06  |      1.52589e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168244           | 334560           | 662057           | 1.29732e+06 |      2.5095e+06  |      4.76138e+06 |      8.80449e+06 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.98854     |      3.9351      | 7.71093     |     14.9158      |     28.3004      |     52.3317      |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.032716    |      0.104646    |      0.18988     | 0.412324    |      0.680216    |      0.799515    |      1.50301     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0167327   |      0.0559247   |      0.0772805   | 0.145464    |      0.237836    |      0.395691    |      0.907546    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0494487   |      0.16057     |      0.267161    | 0.557788    |      0.918052    |      1.19521     |      2.41056     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |     pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |         25,35,80 |        2 batches |        4 batches |   8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |         25,35,80 |         25,35,80 |    25,35,80 |         25,35,80 |         25,35,80 |         25,35,80 |
+=================================================+==================+==================+==================+=============+==================+==================+==================+
| final layer output nodes/pure train time        |      1.68164e+06 |      1.55684e+06 |      1.51197e+06 | 1.5289e+06  | 773159           | 398609           | 205043           |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      9.15244e+06 |      1.60672e+07 |      2.84402e+07 | 5.07545e+07 |      4.42572e+07 |      3.85097e+07 |      3.25639e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.0540788   |      0.0584137   |      0.0601475   | 0.0594811   |      0.117623    |      0.228146    |      0.443522    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average number of nodes for computation         | 494953           | 938547           |      1.71061e+06 | 3.01893e+06 |      5.20564e+06 |      8.78583e+06 |      1.44428e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168037           | 333433           | 658301           | 1.28718e+06 |      2.47996e+06 |      4.67885e+06 |      8.57958e+06 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.98428     |      3.9176      | 7.66013     |     14.7584      |     27.8442      |     51.0577      |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0196621   |      0.103713    |      0.180845    | 0.431047    |      0.64903     |      0.938391    |      1.44869     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0157106   |      0.0463741   |      0.0976734   | 0.1628      |      0.20444     |      0.509717    |      0.773184    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0353727   |      0.150087    |      0.278519    | 0.593847    |      0.85347     |      1.44811     |      2.22188     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |     pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |         25,35,40 |        2 batches |        4 batches |   8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |         25,35,40 |         25,35,40 |    25,35,40 |         25,35,40 |         25,35,40 |         25,35,40 |
+=================================================+==================+==================+==================+=============+==================+==================+==================+
| final layer output nodes/pure train time        |      1.16326e+07 |      1.61758e+06 |      1.03433e+06 | 1.47214e+06 | 692381           | 409692           | 210360           |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      6.29142e+07 |      1.64939e+07 |      1.91173e+07 | 4.78392e+07 |      3.87498e+07 |      3.86155e+07 |      3.24368e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.00781775  |      0.0562205   |      0.0879223   | 0.0617747   |      0.131345    |      0.221974    |      0.432312    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average number of nodes for computation         | 491847           | 927296           |      1.68084e+06 | 2.95525e+06 |      5.0896e+06  |      8.57164e+06 |      1.40228e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 167750           | 332814           | 657074           | 1.2838e+06  |      2.47065e+06 |      4.65271e+06 |      8.49361e+06 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.984       |      3.91701     | 7.65309     |     14.7283      |     27.7361      |     50.6329      |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0250874   |      0.0949621   |      0.148745    | 0.390982    |      0.600756    |      0.939777    |      1.58987     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0154562   |      0.039851    |      0.0734568   | 0.143298    |      0.205981    |      0.388326    |      0.615199    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0405436   |      0.134813    |      0.222202    | 0.53428     |      0.806738    |      1.3281      |      2.20507     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |     pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |         50,70,80 |        2 batches |        4 batches |   8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |         50,70,80 |         50,70,80 |    50,70,80 |         50,70,80 |         50,70,80 |         50,70,80 |
+=================================================+==================+==================+==================+=============+==================+==================+==================+
| final layer output nodes/pure train time        |      1.63483e+06 |      1.5291e+06  |      1.45686e+06 | 1.4591e+06  | 792176           | 432144           | 213526           |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      8.90841e+06 |      1.58379e+07 |      2.75919e+07 | 4.90454e+07 |      4.64239e+07 |      4.35049e+07 |      3.6212e+07  |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.0556271   |      0.0594735   |      0.0624225   | 0.0623267   |      0.114799    |      0.210442    |      0.425901    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average number of nodes for computation         | 495549           | 941938           |      1.72235e+06 | 3.05684e+06 |      5.32942e+06 |      9.15524e+06 |      1.54227e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168346           | 334830           | 663032           | 1.30073e+06 |      2.52095e+06 |      4.80699e+06 |      8.96545e+06 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.98895     |      3.93853     | 7.72658     |     14.9749      |     28.5544      |     53.2564      |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0233345   |      0.095896    |      0.170462    | 0.350378    |      0.61805     |      0.995206    |      1.57179     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0171261   |      0.0531738   |      0.0559669   | 0.215821    |      0.254938    |      0.525698    |      0.899025    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0404606   |      0.14907     |      0.226429    | 0.566199    |      0.872988    |      1.5209      |      2.47082     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
