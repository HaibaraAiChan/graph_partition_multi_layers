computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |   25,35,40,40,40 |        2 batches |        4 batches |        8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |
+=================================================+==================+==================+==================+==================+==================+==================+==================+
| final layer output nodes/pure train time        |      6.08377e+06 |      3.18156e+06 | 843670           | 611902           | 545005           | 249774           | 116690           |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      5.54273e+07 |      5.59442e+07 |      2.80374e+07 |      3.79053e+07 |      6.23984e+07 |      5.25896e+07 |      4.47932e+07 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.0149481   |      0.0285838   |      0.107792    |      0.14862     |      0.166863    |      0.364094    |      0.779335    |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average number of nodes for computation         | 828534           |      1.5991e+06  |      3.02221e+06 |      5.63349e+06 |      1.0412e+07  |      1.91475e+07 |      3.4909e+07  |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168326           | 335630           | 669756           |      1.33574e+06 |      2.65978e+06 |      5.28604e+06 |      1.04785e+07 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.99393     |      3.97892     |      7.93541     |     15.8014      |     31.4036      |     62.2511      |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.032573    |      0.121427    |      0.208305    |      0.447117    |      0.906888    |      1.56015     |      2.74128     |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0291071   |      0.0959651   |      0.162867    |      0.292266    |      0.570881    |      1.16079     |      2.18345     |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0616801   |      0.217392    |      0.371172    |      0.739383    |      1.47777     |      2.72094     |      4.92473     |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
