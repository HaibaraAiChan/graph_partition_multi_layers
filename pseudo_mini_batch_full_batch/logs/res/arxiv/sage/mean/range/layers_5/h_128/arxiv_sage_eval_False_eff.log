computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |   25,35,40,40,40 |        2 batches |        4 batches |        8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |
+=================================================+==================+==================+==================+==================+==================+==================+==================+
| final layer output nodes/pure train time        | 893263           |      3.30664e+06 | 728651           | 580523           | 480645           | 254358           | 126301           |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      8.13897e+06 |      5.81283e+07 |      2.42143e+07 |      3.59503e+07 |      5.50397e+07 |      5.35477e+07 |      4.84746e+07 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.101808    |      0.0275025   |      0.124807    |      0.156654    |      0.189206    |      0.357531    |      0.720036    |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average number of nodes for computation         | 828609           |      1.59868e+06 |      3.02213e+06 |      5.63174e+06 |      1.04139e+07 |      1.91449e+07 |      3.49035e+07 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168335           | 335682           | 669743           |      1.33563e+06 |      2.66058e+06 |      5.28748e+06 |      1.04747e+07 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.99413     |      3.97863     |      7.93433     |     15.8053      |     31.4104      |     62.2254      |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0320954   |      0.159554    |      0.307259    |      0.631033    |      1.16874     |      2.34629     |      4.18453     |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0284879   |      0.0931702   |      0.179783    |      0.319739    |      0.482096    |      1.13577     |      2.12236     |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0605834   |      0.252725    |      0.487041    |      0.950772    |      1.65084     |      3.48205     |      6.30689     |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
