computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |   25,35,40,40,40 |        2 batches |        4 batches |        8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |
+=================================================+==================+==================+==================+==================+==================+==================+==================+
| final layer output nodes/pure train time        |      5.16478e+06 |      2.98551e+06 |      1.74581e+06 | 886051           | 461516           | 214266           | 115973           |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      4.70491e+07 |      5.25091e+07 |      5.80068e+07 |      5.48691e+07 |      5.28614e+07 |      4.51349e+07 |      4.45127e+07 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.0176079   |      0.0304608   |      0.0520909   |      0.102636    |      0.197048    |      0.42443     |      0.784155    |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average number of nodes for computation         | 828438           |      1.59947e+06 |      3.02162e+06 |      5.63156e+06 |      1.04162e+07 |      1.91566e+07 |      3.49048e+07 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168310           | 335684           | 669598           |      1.3358e+06  |      2.66039e+06 |      5.28874e+06 |      1.04763e+07 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.99444     |      3.97836     |      7.93652     |     15.8065      |     31.4226      |     62.2438      |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0363874   |      0.126562    |      0.324331    |      0.534141    |      0.983171    |      1.50502     |      3.16309     |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0289819   |      0.0891957   |      0.153664    |      0.354718    |      0.577917    |      1.023       |      2.16572     |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0653694   |      0.215758    |      0.477996    |      0.888859    |      1.56109     |      2.52802     |      5.32881     |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
