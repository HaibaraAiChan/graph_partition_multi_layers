computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |     pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |         25,70,80 |        2 batches |        4 batches |   8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |         25,70,80 |         25,70,80 |    25,70,80 |         25,70,80 |         25,70,80 |         25,70,80 |
+=================================================+==================+==================+==================+=============+==================+==================+==================+
| final layer output nodes/pure train time        |      2.41124e+06 |      5.05459e+06 |      1.78542e+06 | 1.22132e+06 | 668162           | 376155           | 194225           |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      1.31389e+07 |      4.9061e+07  |      2.95784e+07 | 3.84191e+07 |      3.72286e+07 |      3.57604e+07 |      3.19224e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.0377154   |      0.0179918   |      0.0509353   | 0.0744615   |      0.136106    |      0.241765    |      0.468224    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average number of nodes for computation         | 495539           | 882695           |      1.50658e+06 | 2.86074e+06 |      5.06705e+06 |      8.64559e+06 |      1.49468e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168264           | 330886           | 647026           | 1.27321e+06 |      2.47011e+06 |      4.66152e+06 |      8.68369e+06 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.96647     |      3.84531     | 7.56675     |     14.68        |     27.7036      |     51.6075      |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.029165    |      0.078018    |      0.18593     | 0.248059    |      0.360649    |      0.621183    |      0.960707    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.016819    |      0.0448823   |      0.0847681   | 0.136011    |      0.271235    |      0.364557    |      0.72528     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.045984    |      0.1229      |      0.270698    | 0.38407     |      0.631884    |      0.985741    |      1.68599     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |     pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |         25,35,80 |        2 batches |        4 batches |   8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |         25,35,80 |         25,35,80 |    25,35,80 |         25,35,80 |         25,35,80 |         25,35,80 |
+=================================================+==================+==================+==================+=============+==================+==================+==================+
| final layer output nodes/pure train time        |      1.0771e+07  |      1.62352e+06 |      1.60863e+06 | 1.06434e+06 | 691762           | 321696           | 205103           |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      5.86248e+07 |      1.56939e+07 |      2.61082e+07 | 3.28202e+07 |      3.79616e+07 |      2.98924e+07 |      3.18297e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.00844312  |      0.0560145   |      0.0565333   | 0.0854433   |      0.131463    |      0.282692    |      0.443391    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average number of nodes for computation         | 494976           | 879086           |      1.47598e+06 | 2.80426e+06 |      4.99054e+06 |      8.45033e+06 |      1.4113e+07  |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168039           | 329437           | 642186           | 1.26213e+06 |      2.44363e+06 |      4.59462e+06 |      8.44778e+06 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.96048     |      3.82165     | 7.51093     |     14.5421      |     27.3426      |     50.2728      |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0302181   |      0.0747986   |      0.120699    | 0.240647    |      0.389591    |      0.713075    |      1.21327     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0180581   |      0.0461366   |      0.0495431   | 0.116375    |      0.175647    |      0.415481    |      0.686919    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0482762   |      0.120935    |      0.170242    | 0.357022    |      0.565238    |      1.12856     |      1.90019     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |     pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |         25,35,40 |        2 batches |        4 batches |   8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |         25,35,40 |         25,35,40 |    25,35,40 |         25,35,40 |         25,35,40 |         25,35,40 |
+=================================================+==================+==================+==================+=============+==================+==================+==================+
| final layer output nodes/pure train time        |      9.63704e+06 |      1.64835e+06 |      1.56454e+06 | 1.2915e+06  | 733863           | 348336           | 183455           |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      5.21273e+07 |      1.5736e+07  |      2.5804e+07  | 3.92008e+07 |      3.92024e+07 |      3.1109e+07  |      2.79816e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.00943661  |      0.0551708   |      0.0581262   | 0.0704153   |      0.123921    |      0.261072    |      0.495713    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average number of nodes for computation         | 491905           | 868169           |      1.49989e+06 | 2.76033e+06 |      4.858e+06   |      8.1217e+06  |      1.38708e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 167741           | 328806           | 642872           | 1.25897e+06 |      2.43106e+06 |      4.49026e+06 |      8.44288e+06 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.9602      |      3.83253     | 7.50546     |     14.4929      |     26.769       |     50.3328      |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0236654   |      0.0783069   |      0.148795    | 0.233155    |      0.440066    |      0.561835    |      1.23863     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0149014   |      0.0410759   |      0.0668576   | 0.0982385   |      0.213704    |      0.454963    |      0.744903    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0385668   |      0.119383    |      0.215652    | 0.331394    |      0.653769    |      1.0168      |      1.98353     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |     pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |         50,70,80 |        2 batches |        4 batches |   8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |         50,70,80 |         50,70,80 |    50,70,80 |         50,70,80 |         50,70,80 |         50,70,80 |
+=================================================+==================+==================+==================+=============+==================+==================+==================+
| final layer output nodes/pure train time        |      2.52318e+06 |      4.6121e+06  |      1.58045e+06 | 1.35064e+06 | 747832           | 354191           | 163491           |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      1.37516e+07 |      4.48076e+07 |      2.61591e+07 | 4.24269e+07 |      4.21349e+07 |      3.45668e+07 |      2.68908e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.0360422   |      0.0197179   |      0.0575411   | 0.0673318   |      0.121606    |      0.256757    |      0.556244    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average number of nodes for computation         | 495637           | 883514           |      1.50522e+06 | 2.85668e+06 |      5.12386e+06 |      8.87526e+06 |      1.49578e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168340           | 331368           | 650338           | 1.2803e+06  |      2.49182e+06 |      4.75235e+06 |      8.81285e+06 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.96846     |      3.86326     | 7.60551     |     14.8024      |     28.2308      |     52.3518      |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0252194   |      0.0793688   |      0.132888    | 0.241516    |      0.467645    |      0.747301    |      0.952135    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0174263   |      0.0525537   |      0.074471    | 0.147532    |      0.234936    |      0.608469    |      0.787236    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0426457   |      0.131922    |      0.207359    | 0.389048    |      0.702581    |      1.35577     |      1.73937     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
