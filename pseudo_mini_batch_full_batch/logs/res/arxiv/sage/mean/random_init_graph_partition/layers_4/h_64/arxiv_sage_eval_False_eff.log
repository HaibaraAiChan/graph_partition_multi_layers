computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |      25,35,40,40 |        2 batches |        4 batches |        8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |
+=================================================+==================+==================+==================+==================+==================+==================+==================+
| final layer output nodes/pure train time        |      8.84465e+06 |      1.098e+06   |      1.07761e+06 |      1.06842e+06 |      1.09665e+06 |      1.11512e+06 |      1.06777e+06 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      6.41959e+07 |      1.44821e+07 |      1.42107e+07 |      1.40901e+07 |      1.44038e+07 |      1.4712e+07  |      1.40858e+07 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.010282    |      0.0828245   |      0.0843914   |      0.0851176   |      0.0829265   |      0.0815525   |      0.0851693   |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average number of nodes for computation         | 660065           |      1.19947e+06 |      1.19926e+06 |      1.19932e+06 |      1.19446e+06 |      1.1998e+06  |      1.19967e+06 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168120           | 333698           | 333675           | 333678           | 333662           | 333715           | 333704           |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.98488     |      1.98474     |      1.98476     |      1.98467     |      1.98498     |      1.98492     |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.023541    |      0.117679    |      0.113381    |      0.116379    |      0.0998919   |      0.135043    |      0.0902271   |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0216742   |      0.0807781   |      0.0808802   |      0.0749862   |      0.0563719   |      0.0855324   |      0.0842233   |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0452151   |      0.198457    |      0.194262    |      0.191365    |      0.156264    |      0.220575    |      0.17445     |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
