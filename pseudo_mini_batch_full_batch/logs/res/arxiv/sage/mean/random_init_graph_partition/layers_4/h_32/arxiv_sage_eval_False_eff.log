computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |      25,35,40,40 |        2 batches |        4 batches |        8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |
+=================================================+==================+==================+==================+==================+==================+==================+==================+
| final layer output nodes/pure train time        |      1.37453e+06 |      1.2147e+06  |      1.26075e+06 |      1.27464e+06 |      1.21515e+06 |      1.22167e+06 |      1.22701e+06 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      9.98025e+06 |      1.60747e+07 |      1.66771e+07 |      1.68602e+07 |      1.60772e+07 |      1.6165e+07  |      1.62369e+07 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.0661614   |      0.0748672   |      0.0721326   |      0.0713465   |      0.0748391   |      0.07444     |      0.074116    |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average number of nodes for computation         | 660307           |      1.20347e+06 |      1.20296e+06 |      1.20291e+06 |      1.2032e+06  |      1.20332e+06 |      1.20341e+06 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168135           | 333632           | 333609           | 333675           | 333650           | 333700           | 333678           |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.98431     |      1.98417     |      1.98457     |      1.98442     |      1.98471     |      1.98458     |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0335267   |      0.0982556   |      0.0927761   |      0.092818    |      0.0984018   |      0.106371    |      0.104234    |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0223632   |      0.0722251   |      0.0558715   |      0.0671391   |      0.0725784   |      0.0619392   |      0.0623593   |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0558898   |      0.170481    |      0.148648    |      0.159957    |      0.17098     |      0.168311    |      0.166593    |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
