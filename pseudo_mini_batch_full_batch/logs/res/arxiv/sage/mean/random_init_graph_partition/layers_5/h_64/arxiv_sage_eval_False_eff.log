computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |   25,35,40,40,40 |        2 batches |        4 batches |        8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |   25,35,40,40,40 |
+=================================================+==================+==================+==================+==================+==================+==================+==================+
| final layer output nodes/pure train time        |      5.16478e+06 |      2.74878e+06 |      2.51201e+06 | 818463           |      3.23282e+06 |      3.37102e+06 | 916037           |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      4.70491e+07 |      4.63982e+07 |      4.23959e+07 |      1.38094e+07 |      5.45696e+07 |      5.69012e+07 |      1.54678e+07 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.0176079   |      0.0330842   |      0.0362024   |      0.111112    |      0.0281305   |      0.0269773   |      0.0992765   |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average number of nodes for computation         | 828438           |      1.53505e+06 |      1.53483e+06 |      1.53438e+06 |      1.53507e+06 |      1.53504e+06 |      1.53559e+06 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168310           | 335098           | 335146           | 335208           | 335164           | 335160           | 335162           |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.99095     |      1.99124     |      1.99161     |      1.99135     |      1.99132     |      1.99134     |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0363874   |      0.12967     |      0.129978    |      0.131661    |      0.139781    |      0.134537    |      0.135918    |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0289819   |      0.0783861   |      0.103297    |      0.106083    |      0.100574    |      0.0868881   |      0.083956    |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0653694   |      0.208056    |      0.233275    |      0.237745    |      0.240355    |      0.221426    |      0.219874    |
+-------------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+
