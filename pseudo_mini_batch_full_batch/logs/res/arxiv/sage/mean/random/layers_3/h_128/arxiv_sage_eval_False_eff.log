computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |     pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |         25,70,80 |        2 batches |        4 batches |   8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |         25,70,80 |         25,70,80 |    25,70,80 |         25,70,80 |         25,70,80 |         25,70,80 |
+=================================================+==================+==================+==================+=============+==================+==================+==================+
| final layer output nodes/pure train time        |      1.64793e+06 |      1.61721e+06 |      1.46349e+06 | 1.49229e+06 | 655564           | 387985           | 191600           |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      8.97875e+06 |      1.67457e+07 |      2.77024e+07 | 5.01036e+07 |      3.83361e+07 |      3.88676e+07 |      3.21403e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.0551851   |      0.0562332   |      0.06214     | 0.0609407   |      0.138722    |      0.234393    |      0.474639    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average number of nodes for computation         | 495493           | 941662           |      1.72142e+06 | 3.05335e+06 |      5.31806e+06 |      9.11029e+06 |      1.5255e+07  |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168244           | 334558           | 662065           | 1.2975e+06  |      2.50922e+06 |      4.76118e+06 |      8.80356e+06 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.98853     |      3.93515     | 7.71199     |     14.9142      |     28.2993      |     52.3262      |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.032716    |      0.0668936   |      0.200103    | 0.394285    |      0.5461      |      0.995671    |      1.7935      |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0167327   |      0.053297    |      0.0761912   | 0.145481    |      0.19657     |      0.526453    |      0.7503      |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0494487   |      0.120191    |      0.276294    | 0.539767    |      0.74267     |      1.52212     |      2.5438      |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |     pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |         25,35,80 |        2 batches |        4 batches |   8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |         25,35,80 |         25,35,80 |    25,35,80 |         25,35,80 |         25,35,80 |         25,35,80 |
+=================================================+==================+==================+==================+=============+==================+==================+==================+
| final layer output nodes/pure train time        |      1.68164e+06 |      5.62247e+06 |      1.44706e+06 | 1.52675e+06 | 749138           | 403958           | 216850           |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      9.15244e+06 |      5.80461e+07 |      2.72214e+07 | 5.06885e+07 |      4.29098e+07 |      3.90341e+07 |      3.44135e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.0540788   |      0.0161746   |      0.0628455   | 0.0595651   |      0.121394    |      0.225125    |      0.419374    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average number of nodes for computation         | 494953           | 938870           |      1.71074e+06 | 3.01926e+06 |      5.20899e+06 |      8.78754e+06 |      1.44321e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168037           | 333503           | 658292           | 1.28737e+06 |      2.48108e+06 |      4.67863e+06 |      8.57196e+06 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.9847      |      3.91754     | 7.66121     |     14.7651      |     27.8429      |     51.0123      |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0196621   |      0.10682     |      0.191345    | 0.385673    |      0.639692    |      0.96765     |      1.47546     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0157106   |      0.037509    |      0.0637629   | 0.146338    |      0.211897    |      0.570038    |      0.685209    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0353727   |      0.144329    |      0.255108    | 0.53201     |      0.851589    |      1.53769     |      2.16067     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |     pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |         25,35,40 |        2 batches |        4 batches |   8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |         25,35,40 |         25,35,40 |    25,35,40 |         25,35,40 |         25,35,40 |         25,35,40 |
+=================================================+==================+==================+==================+=============+==================+==================+==================+
| final layer output nodes/pure train time        |      1.16326e+07 |      1.73931e+06 |      2.74413e+06 | 1.46186e+06 | 659567           | 380541           | 212992           |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      6.29142e+07 |      1.77372e+07 |      5.07065e+07 | 4.75127e+07 |      3.69273e+07 |      3.58622e+07 |      3.28451e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.00781775  |      0.0522857   |      0.0331402   | 0.0622089   |      0.13788     |      0.238978    |      0.426969    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average number of nodes for computation         | 491847           | 927404           |      1.68042e+06 | 2.95571e+06 |      5.09153e+06 |      8.5703e+06  |      1.40238e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 167750           | 332836           | 657021           | 1.28416e+06 |      2.4714e+06  |      4.65339e+06 |      8.49792e+06 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.98413     |      3.91669     | 7.65522     |     14.7327      |     27.7402      |     50.6586      |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0250874   |      0.0872867   |      0.215469    | 0.394146    |      0.64613     |      1.01417     |      1.44899     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0154562   |      0.0496886   |      0.0771117   | 0.116275    |      0.250744    |      0.335685    |      0.652645    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0405436   |      0.136975    |      0.292581    | 0.510421    |      0.896873    |      1.34986     |      2.10163     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| arxiv sage                                      |       full batch |          pseudo  |          pseudo  |     pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |         50,70,80 |        2 batches |        4 batches |   8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                  |         50,70,80 |         50,70,80 |    50,70,80 |         50,70,80 |         50,70,80 |         50,70,80 |
+=================================================+==================+==================+==================+=============+==================+==================+==================+
| final layer output nodes/pure train time        |      1.63483e+06 |      1.50446e+06 |      1.34028e+06 | 1.51272e+06 | 644966           | 407238           | 203104           |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |      8.90841e+06 |      1.55834e+07 |      2.53837e+07 | 5.08551e+07 |      3.77823e+07 |      4.10093e+07 |      3.4435e+07  |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.0556271   |      0.0604475   |      0.067852    | 0.0601175   |      0.141001    |      0.223312    |      0.447757    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average number of nodes for computation         | 495549           | 941975           |      1.72234e+06 | 3.05728e+06 |      5.32735e+06 |      9.15786e+06 |      1.54185e+07 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168346           | 334880           | 662926           | 1.30096e+06 |      2.52072e+06 |      4.80719e+06 |      8.96524e+06 |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1           |      1.98925     |      3.9379      | 7.72796     |     14.9736      |     28.5556      |     53.2552      |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0233345   |      0.0837564   |      0.220916    | 0.394869    |      0.48009     |      1.01052     |      1.14275     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0171261   |      0.0619016   |      0.083077    | 0.228953    |      0.215052    |      0.494846    |      0.730906    |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0404606   |      0.145658    |      0.303993    | 0.623822    |      0.695141    |      1.50536     |      1.87365     |
+-------------------------------------------------+------------------+------------------+------------------+-------------+------------------+------------------+------------------+
