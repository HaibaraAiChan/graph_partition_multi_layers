ogbn-arxiv sage,"pseudo 2 batches 25,70,80","pseudo 4 batches 25,70,80","pseudo 8 batches 25,70,80","pseudo 16 batches 25,70,80","pseudo 32 batches 25,70,80","pseudo 64 batches 25,70,80"
Nvidia-smi,OOM,OOM,OOM,22.8026123046875,17.9041748046875,15.8670654296875
CUDA_mem,OOM,OOM,OOM,17.892383098602295,14.474844455718994,11.369403839111328
CUDA_max_mem,OOM,OOM,OOM,18.257999897003174,14.98653507232666,11.996459484100342
epoch_time,,,,63.39167356491089,107.84903502464294,184.88833022117615
pure train_time per epoch,,,,25.246548891067505,46.1185576915741,87.96391654014587
connect checking time per epoch: ,,,,17.985119342803955,29.671142101287842,46.38502264022827
block generation time per epoch: ,,,,16.264767169952393,26.733695030212402,42.98167109489441
batches generation time per epoch: ,,,,1.0165479481220245,0.8354279696941376,0.6715886108577251
first layer input nodes number per epoch,,,,2508966.0,4760599.0,8803745.0
first layer num_input nodes * in_feats per epoch,,,,321147648.0,609356672.0,1126879360.0
logged input_features_size transfer (pointers* Bytes),,,,2304.0,4608.0,9216.0
logged block_size_to_device transfer (pointers*  Bytes),,,,1536.0,3072.0,6144.0
load block tensor time per epoch,,,,0.5551474094390869,1.0645689964294434,1.6493399143218994
block to device time per epoch,,,,0.39545345306396484,0.6924967765808105,1.1010379791259766
