ogbn-arxiv sage,"pseudo 2 batches 25,70,80","pseudo 4 batches 25,70,80","pseudo 8 batches 25,70,80","pseudo 16 batches 25,70,80","pseudo 32 batches 25,70,80","pseudo 64 batches 25,70,80"
Nvidia-smi,OOM,OOM,OOM,OOM,23.4979248046875,19.7615966796875
CUDA_mem,OOM,OOM,OOM,OOM,19.116316318511963,14.269388198852539
CUDA_max_mem,OOM,OOM,OOM,OOM,19.598307609558105,14.708349227905273
epoch_time,,,,,113.78630304336548,189.45164728164673
pure train_time per epoch,,,,,52.8311824798584,92.266606092453
connect checking time per epoch: ,,,,,29.344353199005127,46.484397649765015
block generation time per epoch: ,,,,,26.683194398880005,43.00627613067627
batches generation time per epoch: ,,,,,0.8338498249650002,0.6719730645418167
first layer input nodes number per epoch,,,,,4761007.0,8804296.0
first layer num_input nodes * in_feats per epoch,,,,,609408896.0,1126949888.0
logged input_features_size transfer (pointers* Bytes),,,,,4608.0,9216.0
logged block_size_to_device transfer (pointers*  Bytes),,,,,3072.0,6144.0
load block tensor time per epoch,,,,,0.761307954788208,1.5908448696136475
block to device time per epoch,,,,,0.6699905395507812,1.178360939025879
