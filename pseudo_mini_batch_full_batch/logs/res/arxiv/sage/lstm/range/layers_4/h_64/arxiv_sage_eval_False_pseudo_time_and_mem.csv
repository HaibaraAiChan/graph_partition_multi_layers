ogbn-arxiv sage,"pseudo 2 batches 25,35,40,40","pseudo 4 batches 25,35,40,40","pseudo 8 batches 25,35,40,40","pseudo 16 batches 25,35,40,40","pseudo 32 batches 25,35,40,40","pseudo 64 batches 25,35,40,40"
Nvidia-smi,OOM,OOM,OOM,23.5760498046875,21.8572998046875,19.7166748046875
CUDA_mem,OOM,OOM,OOM,20.347514629364014,18.383380889892578,16.551648139953613
CUDA_max_mem,OOM,OOM,OOM,20.479313373565674,18.660322666168213,16.72762441635132
epoch_time,,,,74.62336277961731,130.73318815231323,230.7718596458435
pure train_time per epoch,,,,14.38257384300232,26.917003631591797,51.365803480148315
connect checking time per epoch: ,,,,30.1720232963562,52.31824588775635,90.01060557365417
block generation time per epoch: ,,,,25.969078540802002,45.84627604484558,80.47594261169434
batches generation time per epoch: ,,,,1.6230674088001251,1.4326961264014244,1.257436603307724
first layer input nodes number per epoch,,,,2618473.0,5144999.0,10008965.0
first layer num_input nodes * in_feats per epoch,,,,335164544.0,658559872.0,1281147520.0
logged input_features_size transfer (pointers* Bytes),,,,2304.0,4608.0,9216.0
logged block_size_to_device transfer (pointers*  Bytes),,,,1536.0,3072.0,6144.0
load block tensor time per epoch,,,,0.6569192409515381,1.311873197555542,2.501121997833252
block to device time per epoch,,,,0.4586946964263916,0.8219261169433594,1.499467134475708
