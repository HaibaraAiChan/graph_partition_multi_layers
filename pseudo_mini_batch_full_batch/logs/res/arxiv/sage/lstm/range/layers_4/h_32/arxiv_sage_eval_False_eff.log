computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| arxiv sage                                      |     full batch |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |    25,35,40,40 |        2 batches |        4 batches |        8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |
+=================================================+================+==================+==================+==================+==================+==================+==================+
| final layer output nodes/pure train time        | 101016         |  51415.3         |  26129.8         |  14049.7         |   6953.66        |   3569.68        |   1818.1         |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         | 733230         | 714259           | 675410           | 663493           | 592416           | 543012           | 486970           |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.900264  |      1.76875     |      3.48035     |      6.47279     |     13.0782      |     25.4759      |     50.0197      |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average number of nodes for computation         | 660101         |      1.26335e+06 |      2.35067e+06 |      4.29464e+06 |      7.7477e+06  |      1.38337e+07 |      2.43581e+07 |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168098         | 334948           | 666657           |      1.32406e+06 |      2.61821e+06 |      5.14504e+06 |      1.00111e+07 |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1         |      1.99258     |      3.96588     |      7.87674     |     15.5755      |     30.6074      |     59.5553      |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0382943 |      0.127322    |      0.183809    |      0.374657    |      0.658163    |      1.24589     |      2.44653     |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0230863 |      0.0785856   |      0.137388    |      0.242407    |      0.454441    |      0.831804    |      1.51205     |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0613806 |      0.205908    |      0.321197    |      0.617064    |      1.1126      |      2.07769     |      3.95858     |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
