computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| arxiv sage                                      |     full batch |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |    25,35,40,40 |        2 batches |        4 batches |        8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |
+=================================================+================+==================+==================+==================+==================+==================+==================+
| final layer output nodes/pure train time        | 101016         |  51403           |  50965           |  52034.3         |  54235.9         |  52145.7         |  53181.1         |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         | 733230         | 677875           | 672722           | 685897           | 715584           | 687896           | 701501           |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.900264  |      1.76918     |      1.78438     |      1.74771     |      1.67677     |      1.74398     |      1.71003     |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average number of nodes for computation         | 660101         |      1.19928e+06 |      1.20039e+06 |      1.19875e+06 |      1.19987e+06 |      1.19968e+06 |      1.19958e+06 |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 168098         | 333640           | 333674           | 333685           | 333679           | 333626           | 333714           |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| redundancy rate (first layer input)             |      1         |      1.98479     |      1.985       |      1.98506     |      1.98503     |      1.98471     |      1.98523     |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0382943 |      0.103534    |      0.0681188   |      0.0924423   |      0.0908859   |      0.0888617   |      0.0911734   |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.0230863 |      0.0843279   |      0.0683918   |      0.0723498   |      0.0623801   |      0.0645211   |      0.0834818   |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0613806 |      0.187861    |      0.136511    |      0.164792    |      0.153266    |      0.153383    |      0.174655    |
+-------------------------------------------------+----------------+------------------+------------------+------------------+------------------+------------------+------------------+
