computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+----------------+------------------+------------------+------------------+-----------------+------------------+------------------+
| arxiv sage                                      |     full batch |          pseudo  |          pseudo  |          pseudo  |         pseudo  |          pseudo  |          pseudo  |
|                                                 |    25,35,40,40 |        2 batches |        4 batches |        8 batches |      16 batches |       32 batches |       64 batches |
|                                                 |                |      25,35,40,40 |      25,35,40,40 |      25,35,40,40 |     25,35,40,40 |      25,35,40,40 |      25,35,40,40 |
+=================================================+================+==================+==================+==================+=================+==================+==================+
| final layer output nodes/pure train time        | 101016         |  53601.1         |  52117.6         |  55441.2         |  46689.7        |  47038.7         |  49237.3         |
+-------------------------------------------------+----------------+------------------+------------------+------------------+-----------------+------------------+------------------+
| all layers input nodes//pure train time         | 733230         | 703553           | 684313           | 728178           | 613059          | 617896           | 646170           |
+-------------------------------------------------+----------------+------------------+------------------+------------------+-----------------+------------------+------------------+
| average train time per epoch                    |      0.900264  |      1.69663     |      1.74492     |      1.64031     |      1.94777    |      1.93332     |      1.847       |
+-------------------------------------------------+----------------+------------------+------------------+------------------+-----------------+------------------+------------------+
| average number of nodes for computation         | 660101         |      1.19367e+06 |      1.19407e+06 |      1.19444e+06 |      1.1941e+06 |      1.19459e+06 |      1.19347e+06 |
+-------------------------------------------------+----------------+------------------+------------------+------------------+-----------------+------------------+------------------+
| average first layer num of input nodes          | 168098         | 333730           | 333646           | 333624           | 333652          | 333653           | 333688           |
+-------------------------------------------------+----------------+------------------+------------------+------------------+-----------------+------------------+------------------+
| redundancy rate (first layer input)             |      1         |      1.98533     |      1.98483     |      1.9847      |      1.98487    |      1.98487     |      1.98508     |
+-------------------------------------------------+----------------+------------------+------------------+------------------+-----------------+------------------+------------------+
| average load block input feature time per epoch |      0.0382943 |      0.0784745   |      0.086201    |      0.100247    |      0.0887411  |      0.0815134   |      0.0806372   |
+-------------------------------------------------+----------------+------------------+------------------+------------------+-----------------+------------------+------------------+
| average block to device time per epoch          |      0.0230863 |      0.0578108   |      0.106649    |      0.0744843   |      0.0780804  |      0.0613685   |      0.0635426   |
+-------------------------------------------------+----------------+------------------+------------------+------------------+-----------------+------------------+------------------+
| average dataloading time per epoch              |      0.0613806 |      0.136285    |      0.19285     |      0.174731    |      0.166821   |      0.142882    |      0.14418     |
+-------------------------------------------------+----------------+------------------+------------------+------------------+-----------------+------------------+------------------+
