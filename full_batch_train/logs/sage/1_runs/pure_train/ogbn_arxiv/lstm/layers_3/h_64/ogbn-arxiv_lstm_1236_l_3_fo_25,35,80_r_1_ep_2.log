Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1648686977.321551
ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
Number of first layer input nodes during this epoch:  168080
----------------------------------------before pred = model(blocks, inputs) 
 Nvidia-smi: 1.2030029296875 GB
    Memory Allocated: 0.11318159103393555  GigaBytes
Max Memory Allocated: 0.11318159103393555  GigaBytes

torch.Size([168080, 128])
torch.Size([167237, 64])
-----------------------------------------pred = model(blocks, inputs) 
 Nvidia-smi: 23.6209716796875 GB
    Memory Allocated: 22.067338943481445  GigaBytes
Max Memory Allocated: 22.318510055541992  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.05519461631774902 |0.356748104095459 |1.4752304553985596 |0.00010395050048828125 |0.9953258037567139 |0.01507258415222168 |
----------------------------------------------------------pseudo_mini_loss sum 4.944904327392578
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  495072
Number of first layer input nodes during this epoch:  168080
Number of first layer input nodes during this epoch:  168021
----------------------------------------before pred = model(blocks, inputs) 
 Nvidia-smi: 19.5115966796875 GB
    Memory Allocated: 0.12926244735717773  GigaBytes
Max Memory Allocated: 22.318510055541992  GigaBytes

torch.Size([168021, 128])
torch.Size([167191, 64])
Traceback (most recent call last):
  File "full_batch_arxiv_sage.py", line 393, in <module>
    main()
  File "full_batch_arxiv_sage.py", line 389, in main
    best_test = run(args, device, data)
  File "full_batch_arxiv_sage.py", line 234, in run
    pred = model(blocks, full_batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/full_batch_train/SAGE/graphsage_model_arxiv.py", line 203, in forward
    x = self.layers[-1](blocks[-1], x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 337, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 156, in invoke_udf_reduce
    retf.update_row(merged_nodes, merged_rst)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/frame.py", line 502, in update_row
    self.add_column(key, scheme, ctx)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/frame.py", line 439, in add_column
    ctx, slice(0, self.num_rows))
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/init.py", line 61, in zero_initializer
    return F.zeros(shape, dtype, ctx)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py", line 220, in zeros
    return th.zeros(shape, dtype=dtype, device=ctx)
RuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 23.62 GiB total capacity; 22.28 GiB already allocated; 22.44 MiB free; 22.38 GiB reserved in total by PyTorch)
