Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1648686938.2358947
ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
Number of first layer input nodes during this epoch:  168251
----------------------------------------before pred = model(blocks, inputs) 
 Nvidia-smi: 1.2030029296875 GB
    Memory Allocated: 0.11530542373657227  GigaBytes
Max Memory Allocated: 0.11530542373657227  GigaBytes

torch.Size([168251, 128])
torch.Size([167483, 32])
-----------------------------------------pred = model(blocks, inputs) 
 Nvidia-smi: 18.6912841796875 GB
    Memory Allocated: 17.352370262145996  GigaBytes
Max Memory Allocated: 17.466647148132324  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03795933723449707 |0.36339569091796875 |1.5492751598358154 |0.00012063980102539062 |1.2532398700714111 |0.008292198181152344 |
----------------------------------------------------------pseudo_mini_loss sum 4.38442325592041
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  495437
Number of first layer input nodes during this epoch:  168251
Number of first layer input nodes during this epoch:  168281
----------------------------------------before pred = model(blocks, inputs) 
 Nvidia-smi: 19.7381591796875 GB
    Memory Allocated: 0.1298842430114746  GigaBytes
Max Memory Allocated: 17.466647148132324  GigaBytes

torch.Size([168281, 128])
torch.Size([167529, 32])
-----------------------------------------pred = model(blocks, inputs) 
 Nvidia-smi: 20.4920654296875 GB
    Memory Allocated: 17.35910129547119  GigaBytes
Max Memory Allocated: 17.486063957214355  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03415417671203613 |0.017699003219604492 |0.6009595394134521 |0.015552043914794922 |1.3023993968963623 |0.0051190853118896484 |
----------------------------------------------------------pseudo_mini_loss sum 3.711758613586426
Total dataloading + training time/epoch 2.62707781791687
Training time/epoch 2.6270053386688232
Training time without block to device /epoch 2.6093063354492188
Training time without total dataloading part /epoch 1.924030065536499
load block tensor time/epoch 0.03415417671203613
block to device time/epoch 0.017699003219604492
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
 Run 0| Epoch 1 |
Number of nodes for computation during this epoch:  495524
Number of first layer input nodes during this epoch:  168281
