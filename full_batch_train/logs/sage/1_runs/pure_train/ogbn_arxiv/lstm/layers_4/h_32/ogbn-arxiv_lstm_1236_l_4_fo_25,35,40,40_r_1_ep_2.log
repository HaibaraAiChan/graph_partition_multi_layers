Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1648687120.618328
ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
Number of first layer input nodes during this epoch:  168087
----------------------------------------before pred = model(blocks, inputs) 
 Nvidia-smi: 1.2225341796875 GB
    Memory Allocated: 0.1253981590270996  GigaBytes
Max Memory Allocated: 0.1253981590270996  GigaBytes

torch.Size([168087, 128])
torch.Size([167834, 32])
torch.Size([166698, 32])
-----------------------------------------pred = model(blocks, inputs) 
 Nvidia-smi: 21.4530029296875 GB
    Memory Allocated: 20.095481395721436  GigaBytes
Max Memory Allocated: 20.19383192062378  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04501914978027344 |0.36127662658691406 |1.3810622692108154 |0.0001666545867919922 |0.5100340843200684 |0.017006397247314453 |
----------------------------------------------------------pseudo_mini_loss sum 4.477881908416748
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  659918
Number of first layer input nodes during this epoch:  168087
Number of first layer input nodes during this epoch:  168109
----------------------------------------before pred = model(blocks, inputs) 
 Nvidia-smi: 22.3924560546875 GB
    Memory Allocated: 0.1405162811279297  GigaBytes
Max Memory Allocated: 20.19383192062378  GigaBytes

torch.Size([168109, 128])
torch.Size([167876, 32])
torch.Size([166767, 32])
-----------------------------------------pred = model(blocks, inputs) 
 Nvidia-smi: 22.3963623046875 GB
    Memory Allocated: 20.113583087921143  GigaBytes
Max Memory Allocated: 20.225378036499023  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.038294315338134766 |0.0230863094329834 |0.37108802795410156 |0.007344484329223633 |0.5140852928161621 |0.007746219635009766 |
----------------------------------------------------------pseudo_mini_loss sum 3.970278739929199
Total dataloading + training time/epoch 1.6581089496612549
Training time/epoch 1.6580278873443604
Training time without block to device /epoch 1.634941577911377
Training time without total dataloading part /epoch 0.9002640247344971
load block tensor time/epoch 0.038294315338134766
block to device time/epoch 0.0230863094329834
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
 Run 0| Epoch 1 |
Number of nodes for computation during this epoch:  660101
Number of first layer input nodes during this epoch:  168109
