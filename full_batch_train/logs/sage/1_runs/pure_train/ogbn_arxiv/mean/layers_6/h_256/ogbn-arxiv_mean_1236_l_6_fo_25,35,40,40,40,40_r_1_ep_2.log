Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1648687268.173673
ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
Number of first layer input nodes during this epoch:  168409
----------------------------------------before pred = model(blocks, inputs) 
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.15312910079956055  GigaBytes
Max Memory Allocated: 0.15312910079956055  GigaBytes

torch.Size([168409, 128])
torch.Size([168324, 256])
torch.Size([168190, 256])
torch.Size([167902, 256])
torch.Size([166747, 256])
-----------------------------------------pred = model(blocks, inputs) 
 Nvidia-smi: 5.1580810546875 GB
    Memory Allocated: 3.5375046730041504  GigaBytes
Max Memory Allocated: 3.6533560752868652  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.06031179428100586 |0.38542604446411133 |0.7890510559082031 |0.00011682510375976562 |0.2986640930175781 |0.008243322372436523 |
----------------------------------------------------------pseudo_mini_loss sum 5.849710464477539
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  996920
Number of first layer input nodes during this epoch:  168409
Number of first layer input nodes during this epoch:  168424
----------------------------------------before pred = model(blocks, inputs) 
 Nvidia-smi: 5.8084716796875 GB
    Memory Allocated: 0.17455720901489258  GigaBytes
Max Memory Allocated: 3.8310327529907227  GigaBytes

torch.Size([168424, 128])
torch.Size([168351, 256])
torch.Size([168193, 256])
torch.Size([167878, 256])
torch.Size([166706, 256])
-----------------------------------------pred = model(blocks, inputs) 
 Nvidia-smi: 5.8104248046875 GB
    Memory Allocated: 3.5452051162719727  GigaBytes
Max Memory Allocated: 3.8310327529907227  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.022124528884887695 |0.03494381904602051 |0.029514789581298828 |0.0001304149627685547 |0.2837405204772949 |0.003358125686645508 |
----------------------------------------------------------pseudo_mini_loss sum 3.775717258453369
Total dataloading + training time/epoch 1.3230490684509277
Training time/epoch 1.322944164276123
Training time without block to device /epoch 1.2880003452301025
Training time without total dataloading part /epoch 0.3167438507080078
load block tensor time/epoch 0.022124528884887695
block to device time/epoch 0.03494381904602051
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 1.1920928955078125e-07
 Run 0| Epoch 1 |
Number of nodes for computation during this epoch:  996859
Number of first layer input nodes during this epoch:  168424
