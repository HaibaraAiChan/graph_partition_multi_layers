Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.
main start at this time 1648687247.7677798
ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
Number of first layer input nodes during this epoch:  168431
----------------------------------------before pred = model(blocks, inputs) 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.1510601043701172  GigaBytes
Max Memory Allocated: 0.1510601043701172  GigaBytes

torch.Size([168431, 128])
torch.Size([168365, 64])
torch.Size([168250, 64])
torch.Size([167937, 64])
torch.Size([166798, 64])
-----------------------------------------pred = model(blocks, inputs) 
 Nvidia-smi: 2.4451904296875 GB
    Memory Allocated: 1.0671992301940918  GigaBytes
Max Memory Allocated: 1.104196548461914  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.06316518783569336 |0.3836653232574463 |0.7821254730224609 |0.00012063980102539062 |0.1070098876953125 |0.007288932800292969 |
----------------------------------------------------------pseudo_mini_loss sum 4.965522766113281
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  997119
Number of first layer input nodes during this epoch:  168431
Number of first layer input nodes during this epoch:  168435
----------------------------------------before pred = model(blocks, inputs) 
 Nvidia-smi: 2.6815185546875 GB
    Memory Allocated: 0.16820621490478516  GigaBytes
Max Memory Allocated: 1.1438264846801758  GigaBytes

torch.Size([168435, 128])
torch.Size([168375, 64])
torch.Size([168233, 64])
torch.Size([167936, 64])
torch.Size([166789, 64])
-----------------------------------------pred = model(blocks, inputs) 
 Nvidia-smi: 2.6834716796875 GB
    Memory Allocated: 1.069094181060791  GigaBytes
Max Memory Allocated: 1.1438264846801758  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03362154960632324 |0.03476309776306152 |0.008758068084716797 |0.00012946128845214844 |0.0915217399597168 |0.005487203598022461 |
----------------------------------------------------------pseudo_mini_loss sum 4.014958381652832
Total dataloading + training time/epoch 0.9645233154296875
Training time/epoch 0.9644324779510498
Training time without block to device /epoch 0.9296693801879883
Training time without total dataloading part /epoch 0.1058964729309082
load block tensor time/epoch 0.03362154960632324
block to device time/epoch 0.03476309776306152
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 1.1920928955078125e-07
 Run 0| Epoch 1 |
Number of nodes for computation during this epoch:  997087
Number of first layer input nodes during this epoch:  168435
